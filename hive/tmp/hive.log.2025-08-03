2025-08-03T13:06:58,751  INFO [main] conf.MetastoreConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T13:06:59,125  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T13:06:59,126  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T13:06:59,126  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T13:06:59,126  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T13:06:59,221  INFO [main] metastore.HiveMetaStore: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting HiveMetaStore
STARTUP_MSG:   host = 6eac2c46c474/172.18.0.6
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.3
STARTUP_MSG:   classpath = /opt/hive/conf:/opt/hive/lib/HikariCP-2.6.1.jar:/opt/hive/lib/JavaEWAH-0.3.2.jar:/opt/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hive/lib/ST4-4.0.4.jar:/opt/hive/lib/accumulo-core-1.7.3.jar:/opt/hive/lib/accumulo-fate-1.7.3.jar:/opt/hive/lib/accumulo-start-1.7.3.jar:/opt/hive/lib/accumulo-trace-1.7.3.jar:/opt/hive/lib/aircompressor-0.10.jar:/opt/hive/lib/ant-1.9.1.jar:/opt/hive/lib/ant-launcher-1.9.1.jar:/opt/hive/lib/antlr-runtime-3.5.2.jar:/opt/hive/lib/antlr4-runtime-4.5.jar:/opt/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hive/lib/arrow-format-0.8.0.jar:/opt/hive/lib/arrow-memory-0.8.0.jar:/opt/hive/lib/arrow-vector-0.8.0.jar:/opt/hive/lib/asm-5.0.1.jar:/opt/hive/lib/asm-commons-5.0.1.jar:/opt/hive/lib/asm-tree-5.0.1.jar:/opt/hive/lib/audience-annotations-0.5.0.jar:/opt/hive/lib/avatica-1.11.0.jar:/opt/hive/lib/avro-1.8.2.jar:/opt/hive/lib/avro-ipc-1.8.2.jar:/opt/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.375.jar:/opt/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hive/lib/calcite-core-1.16.0.jar:/opt/hive/lib/calcite-druid-1.16.0.jar:/opt/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hive/lib/chill-java-0.8.4.jar:/opt/hive/lib/chill_2.11-0.8.4.jar:/opt/hive/lib/commons-cli-1.2.jar:/opt/hive/lib/commons-codec-1.15.jar:/opt/hive/lib/commons-collections4-4.1.jar:/opt/hive/lib/commons-compiler-2.7.6.jar:/opt/hive/lib/commons-compress-1.19.jar:/opt/hive/lib/commons-crypto-1.0.0.jar:/opt/hive/lib/commons-dbcp-1.4.jar:/opt/hive/lib/commons-io-2.6.jar:/opt/hive/lib/commons-lang-2.6.jar:/opt/hive/lib/commons-lang3-3.9.jar:/opt/hive/lib/commons-logging-1.0.4.jar:/opt/hive/lib/commons-math-2.1.jar:/opt/hive/lib/commons-math3-3.6.1.jar:/opt/hive/lib/commons-pool-1.5.4.jar:/opt/hive/lib/commons-vfs2-2.1.jar:/opt/hive/lib/compress-lzf-1.0.3.jar:/opt/hive/lib/curator-client-2.12.0.jar:/opt/hive/lib/curator-framework-2.12.0.jar:/opt/hive/lib/curator-recipes-2.12.0.jar:/opt/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hive/lib/datanucleus-core-4.1.17.jar:/opt/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hive/lib/derby-10.14.1.0.jar:/opt/hive/lib/disruptor-3.3.6.jar:/opt/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hive/lib/ecj-4.4.2.jar:/opt/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hive/lib/groovy-all-2.4.11.jar:/opt/hive/lib/gson-2.2.4.jar:/opt/hive/lib/guava-19.0.jar:/opt/hive/lib/hadoop-aws-3.1.2.jar:/opt/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hive/lib/hive-beeline-3.1.3.jar:/opt/hive/lib/hive-classification-3.1.3.jar:/opt/hive/lib/hive-cli-3.1.3.jar:/opt/hive/lib/hive-common-3.1.3.jar:/opt/hive/lib/hive-contrib-3.1.3.jar:/opt/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hive/lib/hive-exec-3.1.3.jar:/opt/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hive/lib/hive-hplsql-3.1.3.jar:/opt/hive/lib/hive-jdbc-3.1.3.jar:/opt/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hive/lib/hive-llap-client-3.1.3.jar:/opt/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hive/lib/hive-llap-common-3.1.3.jar:/opt/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hive/lib/hive-llap-server-3.1.3.jar:/opt/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hive/lib/hive-metastore-3.1.3.jar:/opt/hive/lib/hive-serde-3.1.3.jar:/opt/hive/lib/hive-service-3.1.3.jar:/opt/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hive/lib/hive-shims-3.1.3.jar:/opt/hive/lib/hive-shims-common-3.1.3.jar:/opt/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hive/lib/hive-spark-client-3.1.3.jar:/opt/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hive/lib/hive-storage-api-2.7.0.jar:/opt/hive/lib/hive-streaming-3.1.3.jar:/opt/hive/lib/hive-testutils-3.1.3.jar:/opt/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hive/lib/hppc-0.7.2.jar:/opt/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hive/lib/httpclient-4.5.13.jar:/opt/hive/lib/httpcore-4.4.13.jar:/opt/hive/lib/ivy-2.4.0.jar:/opt/hive/lib/jackson-annotations-2.12.0.jar:/opt/hive/lib/jackson-core-2.12.0.jar:/opt/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hive/lib/jackson-databind-2.12.0.jar:/opt/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hive/lib/jamon-runtime-2.3.1.jar:/opt/hive/lib/janino-2.7.6.jar:/opt/hive/lib/javassist-3.20.0-GA.jar:/opt/hive/lib/javax.annotation-api-1.2.jar:/opt/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hive/lib/javolution-5.5.1.jar:/opt/hive/lib/jaxb-api-2.2.11.jar:/opt/hive/lib/jcodings-1.0.18.jar:/opt/hive/lib/jcommander-1.32.jar:/opt/hive/lib/jdo-api-3.0.1.jar:/opt/hive/lib/jersey-client-2.25.1.jar:/opt/hive/lib/jersey-common-2.25.1.jar:/opt/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hive/lib/jersey-guava-2.25.1.jar:/opt/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hive/lib/jersey-server-2.25.1.jar:/opt/hive/lib/jettison-1.1.jar:/opt/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hive/lib/jetty-schemas-3.1.jar:/opt/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hive/lib/jline-2.12.jar:/opt/hive/lib/joda-time-2.9.9.jar:/opt/hive/lib/jodd-core-3.5.2.jar:/opt/hive/lib/joni-2.1.11.jar:/opt/hive/lib/jpam-1.1.jar:/opt/hive/lib/json-1.8.jar:/opt/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hive/lib/jsr305-3.0.0.jar:/opt/hive/lib/jta-1.1.jar:/opt/hive/lib/kryo-shaded-3.0.3.jar:/opt/hive/lib/libfb303-0.9.3.jar:/opt/hive/lib/libthrift-0.9.3.jar:/opt/hive/lib/lz4-java-1.4.0.jar:/opt/hive/lib/memory-0.9.0.jar:/opt/hive/lib/metrics-core-3.1.0.jar:/opt/hive/lib/metrics-graphite-3.1.5.jar:/opt/hive/lib/metrics-json-3.1.0.jar:/opt/hive/lib/metrics-jvm-3.1.0.jar:/opt/hive/lib/minlog-1.3.0.jar:/opt/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hive/lib/netty-3.10.5.Final.jar:/opt/hive/lib/netty-all-4.1.17.Final.jar:/opt/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hive/lib/netty-common-4.1.17.Final.jar:/opt/hive/lib/objenesis-2.1.jar:/opt/hive/lib/opencsv-2.3.jar:/opt/hive/lib/opencsv-3.9.jar:/opt/hive/lib/orc-core-1.5.8.jar:/opt/hive/lib/orc-shims-1.5.8.jar:/opt/hive/lib/orc-tools-1.5.8.jar:/opt/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hive/lib/paranamer-2.7.jar:/opt/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hive/lib/postgresql-42.7.7.jar:/opt/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hive/lib/protobuf-java-2.5.0.jar:/opt/hive/lib/py4j-0.10.6.jar:/opt/hive/lib/pyrolite-4.13.jar:/opt/hive/lib/scala-compiler-2.11.0.jar:/opt/hive/lib/scala-library-2.11.8.jar:/opt/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hive/lib/scala-reflect-2.11.0.jar:/opt/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hive/lib/scalap-2.11.0.jar:/opt/hive/lib/sketches-core-0.9.0.jar:/opt/hive/lib/snappy-java-1.1.4.jar:/opt/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hive/lib/sqlline-1.3.0.jar:/opt/hive/lib/stax-api-1.0.1.jar:/opt/hive/lib/stream-2.7.0.jar:/opt/hive/lib/super-csv-2.2.0.jar:/opt/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hive/lib/tempus-fugit-1.1.jar:/opt/hive/lib/threetenbp-1.3.5.jar:/opt/hive/lib/transaction-api-1.1.jar:/opt/hive/lib/unused-1.0.0.jar:/opt/hive/lib/validation-api-1.1.0.Final.jar:/opt/hive/lib/velocity-1.7.jar:/opt/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hive/lib/xz-1.5.jar:/opt/hive/lib/zookeeper-3.4.6.jar:/opt/hive/lib/zstd-jni-1.3.2-2.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.1.0.jar:/opt/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hive/lib/log4j-api-2.17.1.jar:/opt/hive/lib/log4j-core-2.17.1.jar:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar
STARTUP_MSG:   build = git://MacBook-Pro.fios-router.home/Users/ngangam/commit/hive -r 4df4d75bf1e16fe0af75aad0b4179c34c07fc975; compiled by 'ngangam' on Sun Apr 3 16:58:33 EDT 2022
************************************************************/
2025-08-03T13:06:59,280  INFO [main] metastore.HiveMetaStore: Starting hive metastore on port 9083
2025-08-03T13:06:59,465  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T13:06:59,562  WARN [main] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T13:06:59,571  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T13:06:59,572  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T13:06:59,572  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T13:06:59,573  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T13:06:59,573  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T13:07:00,131  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2025-08-03T13:07:00,539  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2025-08-03T13:07:00,600  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2025-08-03T13:07:00,639  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2025-08-03T13:07:00,815  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-03T13:07:00,946  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T13:07:00,953  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T13:07:04,058  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2025-08-03T13:07:04,061  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2025-08-03T13:07:04,081  INFO [main] metastore.HiveMetaStore: No user is added in admin role, since config is empty
2025-08-03T13:07:04,161  INFO [main] conf.HiveConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T13:07:04,374  INFO [main] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2025-08-03T13:07:04,379  INFO [main] metastore.HiveMetaStore: Started the new metaserver on port [9083]...
2025-08-03T13:07:04,379  INFO [main] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2025-08-03T13:07:04,380  INFO [main] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2025-08-03T13:07:04,380  INFO [main] metastore.HiveMetaStore: TCP keepalive = true
2025-08-03T13:07:04,380  INFO [main] metastore.HiveMetaStore: Enable SSL = false
2025-08-03T13:08:24,398  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Done cleaning up thread local RawStore
2025-08-03T13:08:24,399  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:34,288 ERROR [pool-6-thread-2] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:34,306  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: Done cleaning up thread local RawStore
2025-08-03T13:09:34,307  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:34,581 ERROR [pool-6-thread-3] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:34,582  INFO [pool-6-thread-3] metastore.HiveMetaStore: 3: Done cleaning up thread local RawStore
2025-08-03T13:09:34,582  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:34,589 ERROR [pool-6-thread-4] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:34,589  INFO [pool-6-thread-4] metastore.HiveMetaStore: 4: Done cleaning up thread local RawStore
2025-08-03T13:09:34,589  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:34,603 ERROR [pool-6-thread-5] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:34,605  INFO [pool-6-thread-5] metastore.HiveMetaStore: 5: Done cleaning up thread local RawStore
2025-08-03T13:09:34,605  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:34,803 ERROR [pool-6-thread-6] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:34,804  INFO [pool-6-thread-6] metastore.HiveMetaStore: 6: Done cleaning up thread local RawStore
2025-08-03T13:09:34,804  INFO [pool-6-thread-6] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:36,134 ERROR [pool-6-thread-7] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:36,135  INFO [pool-6-thread-7] metastore.HiveMetaStore: 7: Done cleaning up thread local RawStore
2025-08-03T13:09:36,135  INFO [pool-6-thread-7] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:36,140 ERROR [pool-6-thread-8] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:36,141  INFO [pool-6-thread-8] metastore.HiveMetaStore: 8: Done cleaning up thread local RawStore
2025-08-03T13:09:36,141  INFO [pool-6-thread-8] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:36,149 ERROR [pool-6-thread-9] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:36,150  INFO [pool-6-thread-9] metastore.HiveMetaStore: 9: Done cleaning up thread local RawStore
2025-08-03T13:09:36,150  INFO [pool-6-thread-9] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:37,182 ERROR [pool-6-thread-10] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:37,183  INFO [pool-6-thread-10] metastore.HiveMetaStore: 10: Done cleaning up thread local RawStore
2025-08-03T13:09:37,183  INFO [pool-6-thread-10] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:37,840 ERROR [pool-6-thread-11] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:37,843  INFO [pool-6-thread-11] metastore.HiveMetaStore: 11: Done cleaning up thread local RawStore
2025-08-03T13:09:37,843  INFO [pool-6-thread-11] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:37,847 ERROR [pool-6-thread-12] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:37,848  INFO [pool-6-thread-12] metastore.HiveMetaStore: 12: Done cleaning up thread local RawStore
2025-08-03T13:09:37,848  INFO [pool-6-thread-12] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:09:37,856 ERROR [pool-6-thread-13] server.TThreadPoolServer: Thrift error occurred during processing of message.
org.apache.thrift.protocol.TProtocolException: Missing version in readMessageBegin, old client?
	at org.apache.thrift.protocol.TBinaryProtocol.readMessageBegin(TBinaryProtocol.java:228) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:76) ~[hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
2025-08-03T13:09:37,856  INFO [pool-6-thread-13] metastore.HiveMetaStore: 13: Done cleaning up thread local RawStore
2025-08-03T13:09:37,857  INFO [pool-6-thread-13] HiveMetaStore.audit: ugi=hive	ip=172.18.0.1	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:12:07,902  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: source:172.18.0.4 get_database: default
2025-08-03T13:12:07,908  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=spark	ip=172.18.0.4	cmd=source:172.18.0.4 get_database: default	
2025-08-03T13:12:07,909  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T13:12:07,910  WARN [pool-6-thread-14] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T13:12:07,910  INFO [pool-6-thread-14] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T13:12:07,934  INFO [pool-6-thread-14] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T13:12:07,934  INFO [pool-6-thread-14] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T13:12:07,953  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: source:172.18.0.4 get_database: smartlogistics
2025-08-03T13:12:07,953  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=spark	ip=172.18.0.4	cmd=source:172.18.0.4 get_database: smartlogistics	
2025-08-03T13:12:07,956  WARN [pool-6-thread-14] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:12:07,966  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: source:172.18.0.4 get_database: smartlogistics
2025-08-03T13:12:07,967  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=spark	ip=172.18.0.4	cmd=source:172.18.0.4 get_database: smartlogistics	
2025-08-03T13:12:07,969  WARN [pool-6-thread-14] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:12:07,977  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: source:172.18.0.4 get_database: global_temp
2025-08-03T13:12:07,977  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=spark	ip=172.18.0.4	cmd=source:172.18.0.4 get_database: global_temp	
2025-08-03T13:12:07,980  WARN [pool-6-thread-14] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T13:12:08,002  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: source:172.18.0.4 create_database: Database(name:smartlogistics, description:, locationUri:file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T13:12:08,002  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=spark	ip=172.18.0.4	cmd=source:172.18.0.4 create_database: Database(name:smartlogistics, description:, locationUri:file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T13:12:08,005  WARN [pool-6-thread-14] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:12:08,365  INFO [pool-6-thread-14] utils.FileUtils: Creating directory if it doesn't exist: file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db
2025-08-03T13:12:08,396 ERROR [pool-6-thread-14] metastore.RetryingHMSHandler: MetaException(message:Unable to create database path file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db, failed to create database smartlogistics)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1267)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2025-08-03T13:12:09,597  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: source:172.18.0.4 get_database: smartlogistics
2025-08-03T13:12:09,597  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=spark	ip=172.18.0.4	cmd=source:172.18.0.4 get_database: smartlogistics	
2025-08-03T13:12:09,619  WARN [pool-6-thread-14] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:14:26,262  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: Cleaning up thread local RawStore...
2025-08-03T13:14:26,263  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=hive	ip=172.18.0.4	cmd=Cleaning up thread local RawStore...	
2025-08-03T13:14:26,264  INFO [pool-6-thread-14] metastore.HiveMetaStore: 14: Done cleaning up thread local RawStore
2025-08-03T13:14:26,264  INFO [pool-6-thread-14] HiveMetaStore.audit: ugi=hive	ip=172.18.0.4	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:16:19,568  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: source:172.18.0.5 get_database: default
2025-08-03T13:16:19,569  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: default	
2025-08-03T13:16:19,572  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T13:16:19,572  WARN [pool-6-thread-15] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T13:16:19,573  INFO [pool-6-thread-15] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T13:16:19,586  INFO [pool-6-thread-15] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T13:16:19,586  INFO [pool-6-thread-15] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T13:16:19,597  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:16:19,597  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:16:19,600  WARN [pool-6-thread-15] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:16:19,604  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:16:19,605  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:16:19,609  WARN [pool-6-thread-15] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:16:19,615  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: source:172.18.0.5 get_database: global_temp
2025-08-03T13:16:19,616  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: global_temp	
2025-08-03T13:16:19,619  WARN [pool-6-thread-15] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T13:16:19,627  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: source:172.18.0.5 create_database: Database(name:smartlogistics, description:, locationUri:file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T13:16:19,627  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 create_database: Database(name:smartlogistics, description:, locationUri:file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T13:16:19,629  WARN [pool-6-thread-15] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:16:19,636  INFO [pool-6-thread-15] utils.FileUtils: Creating directory if it doesn't exist: file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db
2025-08-03T13:16:19,637 ERROR [pool-6-thread-15] metastore.RetryingHMSHandler: MetaException(message:Unable to create database path file:/opt/bitnami/spark/spark-warehouse/smartlogistics.db, failed to create database smartlogistics)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1267)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2025-08-03T13:16:20,755  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:16:20,756  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:16:20,759  WARN [pool-6-thread-15] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:17:17,344  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: Cleaning up thread local RawStore...
2025-08-03T13:17:17,345  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T13:17:17,346  INFO [pool-6-thread-15] metastore.HiveMetaStore: 15: Done cleaning up thread local RawStore
2025-08-03T13:17:17,346  INFO [pool-6-thread-15] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:17:53,353  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: source:172.18.0.5 get_database: default
2025-08-03T13:17:53,353  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: default	
2025-08-03T13:17:53,356  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T13:17:53,356  WARN [pool-6-thread-16] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T13:17:53,357  INFO [pool-6-thread-16] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T13:17:53,367  INFO [pool-6-thread-16] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T13:17:53,367  INFO [pool-6-thread-16] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T13:17:53,378  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:17:53,378  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:17:53,382  WARN [pool-6-thread-16] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:17:53,385  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:17:53,385  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:17:53,389  WARN [pool-6-thread-16] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:17:53,396  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: source:172.18.0.5 get_database: global_temp
2025-08-03T13:17:53,396  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: global_temp	
2025-08-03T13:17:53,399  WARN [pool-6-thread-16] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T13:17:53,407  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: source:172.18.0.5 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T13:17:53,408  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T13:17:53,410  WARN [pool-6-thread-16] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:17:53,422 ERROR [pool-6-thread-16] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T13:17:54,466  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:17:54,466  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:17:54,469  WARN [pool-6-thread-16] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:18:35,109  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: Cleaning up thread local RawStore...
2025-08-03T13:18:35,110  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T13:18:35,110  INFO [pool-6-thread-16] metastore.HiveMetaStore: 16: Done cleaning up thread local RawStore
2025-08-03T13:18:35,110  INFO [pool-6-thread-16] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T13:33:20,390  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: source:172.18.0.5 get_database: default
2025-08-03T13:33:20,398  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: default	
2025-08-03T13:33:20,406  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T13:33:20,408  WARN [pool-6-thread-17] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T13:33:20,411  INFO [pool-6-thread-17] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T13:33:20,467  INFO [pool-6-thread-17] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T13:33:20,467  INFO [pool-6-thread-17] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T13:33:20,488  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:33:20,488  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:33:20,492  WARN [pool-6-thread-17] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:33:20,498  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: source:172.18.0.5 get_database: smartlogistics
2025-08-03T13:33:20,498  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: smartlogistics	
2025-08-03T13:33:20,502  WARN [pool-6-thread-17] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:33:20,511  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: source:172.18.0.5 get_database: global_temp
2025-08-03T13:33:20,512  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 get_database: global_temp	
2025-08-03T13:33:20,515  WARN [pool-6-thread-17] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T13:33:20,524  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: source:172.18.0.5 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T13:33:20,525  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=spark	ip=172.18.0.5	cmd=source:172.18.0.5 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T13:33:20,528  WARN [pool-6-thread-17] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T13:33:20,549 ERROR [pool-6-thread-17] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T13:53:05,638  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: Cleaning up thread local RawStore...
2025-08-03T13:53:05,640  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T13:53:05,643  INFO [pool-6-thread-17] metastore.HiveMetaStore: 17: Done cleaning up thread local RawStore
2025-08-03T13:53:05,643  INFO [pool-6-thread-17] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T14:07:26,693  INFO [pool-4-thread-1] metastore.HiveMetaStore: 18: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T14:07:26,695  WARN [pool-4-thread-1] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T14:07:26,697  INFO [pool-4-thread-1] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T14:07:26,739  INFO [pool-4-thread-1] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T14:07:26,740  INFO [pool-4-thread-1] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T14:17:59,044  INFO [pool-2-thread-1] metastore.HiveMetaStore: Shutting down hive metastore.
2025-08-03T14:17:59,048  INFO [pool-2-thread-1] metastore.HiveMetaStore: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down HiveMetaStore at 6eac2c46c474/172.18.0.6
************************************************************/
2025-08-03T14:18:47,734  INFO [main] conf.MetastoreConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T14:18:48,130  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T14:18:48,131  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:18:48,133  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T14:18:48,133  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:18:48,228  INFO [main] metastore.HiveMetaStore: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting HiveMetaStore
STARTUP_MSG:   host = 086139701e19/172.18.0.4
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.3
STARTUP_MSG:   classpath = /opt/hive/conf:/opt/hive/lib/HikariCP-2.6.1.jar:/opt/hive/lib/JavaEWAH-0.3.2.jar:/opt/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hive/lib/ST4-4.0.4.jar:/opt/hive/lib/accumulo-core-1.7.3.jar:/opt/hive/lib/accumulo-fate-1.7.3.jar:/opt/hive/lib/accumulo-start-1.7.3.jar:/opt/hive/lib/accumulo-trace-1.7.3.jar:/opt/hive/lib/aircompressor-0.10.jar:/opt/hive/lib/ant-1.9.1.jar:/opt/hive/lib/ant-launcher-1.9.1.jar:/opt/hive/lib/antlr-runtime-3.5.2.jar:/opt/hive/lib/antlr4-runtime-4.5.jar:/opt/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hive/lib/arrow-format-0.8.0.jar:/opt/hive/lib/arrow-memory-0.8.0.jar:/opt/hive/lib/arrow-vector-0.8.0.jar:/opt/hive/lib/asm-5.0.1.jar:/opt/hive/lib/asm-commons-5.0.1.jar:/opt/hive/lib/asm-tree-5.0.1.jar:/opt/hive/lib/audience-annotations-0.5.0.jar:/opt/hive/lib/avatica-1.11.0.jar:/opt/hive/lib/avro-1.8.2.jar:/opt/hive/lib/avro-ipc-1.8.2.jar:/opt/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.375.jar:/opt/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hive/lib/calcite-core-1.16.0.jar:/opt/hive/lib/calcite-druid-1.16.0.jar:/opt/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hive/lib/chill-java-0.8.4.jar:/opt/hive/lib/chill_2.11-0.8.4.jar:/opt/hive/lib/commons-cli-1.2.jar:/opt/hive/lib/commons-codec-1.15.jar:/opt/hive/lib/commons-collections4-4.1.jar:/opt/hive/lib/commons-compiler-2.7.6.jar:/opt/hive/lib/commons-compress-1.19.jar:/opt/hive/lib/commons-crypto-1.0.0.jar:/opt/hive/lib/commons-dbcp-1.4.jar:/opt/hive/lib/commons-io-2.6.jar:/opt/hive/lib/commons-lang-2.6.jar:/opt/hive/lib/commons-lang3-3.9.jar:/opt/hive/lib/commons-logging-1.0.4.jar:/opt/hive/lib/commons-math-2.1.jar:/opt/hive/lib/commons-math3-3.6.1.jar:/opt/hive/lib/commons-pool-1.5.4.jar:/opt/hive/lib/commons-vfs2-2.1.jar:/opt/hive/lib/compress-lzf-1.0.3.jar:/opt/hive/lib/curator-client-2.12.0.jar:/opt/hive/lib/curator-framework-2.12.0.jar:/opt/hive/lib/curator-recipes-2.12.0.jar:/opt/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hive/lib/datanucleus-core-4.1.17.jar:/opt/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hive/lib/derby-10.14.1.0.jar:/opt/hive/lib/disruptor-3.3.6.jar:/opt/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hive/lib/ecj-4.4.2.jar:/opt/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hive/lib/groovy-all-2.4.11.jar:/opt/hive/lib/gson-2.2.4.jar:/opt/hive/lib/guava-19.0.jar:/opt/hive/lib/hadoop-aws-3.1.2.jar:/opt/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hive/lib/hive-beeline-3.1.3.jar:/opt/hive/lib/hive-classification-3.1.3.jar:/opt/hive/lib/hive-cli-3.1.3.jar:/opt/hive/lib/hive-common-3.1.3.jar:/opt/hive/lib/hive-contrib-3.1.3.jar:/opt/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hive/lib/hive-exec-3.1.3.jar:/opt/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hive/lib/hive-hplsql-3.1.3.jar:/opt/hive/lib/hive-jdbc-3.1.3.jar:/opt/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hive/lib/hive-llap-client-3.1.3.jar:/opt/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hive/lib/hive-llap-common-3.1.3.jar:/opt/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hive/lib/hive-llap-server-3.1.3.jar:/opt/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hive/lib/hive-metastore-3.1.3.jar:/opt/hive/lib/hive-serde-3.1.3.jar:/opt/hive/lib/hive-service-3.1.3.jar:/opt/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hive/lib/hive-shims-3.1.3.jar:/opt/hive/lib/hive-shims-common-3.1.3.jar:/opt/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hive/lib/hive-spark-client-3.1.3.jar:/opt/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hive/lib/hive-storage-api-2.7.0.jar:/opt/hive/lib/hive-streaming-3.1.3.jar:/opt/hive/lib/hive-testutils-3.1.3.jar:/opt/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hive/lib/hppc-0.7.2.jar:/opt/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hive/lib/httpclient-4.5.13.jar:/opt/hive/lib/httpcore-4.4.13.jar:/opt/hive/lib/ivy-2.4.0.jar:/opt/hive/lib/jackson-annotations-2.12.0.jar:/opt/hive/lib/jackson-core-2.12.0.jar:/opt/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hive/lib/jackson-databind-2.12.0.jar:/opt/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hive/lib/jamon-runtime-2.3.1.jar:/opt/hive/lib/janino-2.7.6.jar:/opt/hive/lib/javassist-3.20.0-GA.jar:/opt/hive/lib/javax.annotation-api-1.2.jar:/opt/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hive/lib/javolution-5.5.1.jar:/opt/hive/lib/jaxb-api-2.2.11.jar:/opt/hive/lib/jcodings-1.0.18.jar:/opt/hive/lib/jcommander-1.32.jar:/opt/hive/lib/jdo-api-3.0.1.jar:/opt/hive/lib/jersey-client-2.25.1.jar:/opt/hive/lib/jersey-common-2.25.1.jar:/opt/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hive/lib/jersey-guava-2.25.1.jar:/opt/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hive/lib/jersey-server-2.25.1.jar:/opt/hive/lib/jettison-1.1.jar:/opt/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hive/lib/jetty-schemas-3.1.jar:/opt/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hive/lib/jline-2.12.jar:/opt/hive/lib/joda-time-2.9.9.jar:/opt/hive/lib/jodd-core-3.5.2.jar:/opt/hive/lib/joni-2.1.11.jar:/opt/hive/lib/jpam-1.1.jar:/opt/hive/lib/json-1.8.jar:/opt/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hive/lib/jsr305-3.0.0.jar:/opt/hive/lib/jta-1.1.jar:/opt/hive/lib/kryo-shaded-3.0.3.jar:/opt/hive/lib/libfb303-0.9.3.jar:/opt/hive/lib/libthrift-0.9.3.jar:/opt/hive/lib/lz4-java-1.4.0.jar:/opt/hive/lib/memory-0.9.0.jar:/opt/hive/lib/metrics-core-3.1.0.jar:/opt/hive/lib/metrics-graphite-3.1.5.jar:/opt/hive/lib/metrics-json-3.1.0.jar:/opt/hive/lib/metrics-jvm-3.1.0.jar:/opt/hive/lib/minlog-1.3.0.jar:/opt/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hive/lib/netty-3.10.5.Final.jar:/opt/hive/lib/netty-all-4.1.17.Final.jar:/opt/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hive/lib/netty-common-4.1.17.Final.jar:/opt/hive/lib/objenesis-2.1.jar:/opt/hive/lib/opencsv-2.3.jar:/opt/hive/lib/opencsv-3.9.jar:/opt/hive/lib/orc-core-1.5.8.jar:/opt/hive/lib/orc-shims-1.5.8.jar:/opt/hive/lib/orc-tools-1.5.8.jar:/opt/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hive/lib/paranamer-2.7.jar:/opt/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hive/lib/postgresql-42.7.7.jar:/opt/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hive/lib/protobuf-java-2.5.0.jar:/opt/hive/lib/py4j-0.10.6.jar:/opt/hive/lib/pyrolite-4.13.jar:/opt/hive/lib/scala-compiler-2.11.0.jar:/opt/hive/lib/scala-library-2.11.8.jar:/opt/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hive/lib/scala-reflect-2.11.0.jar:/opt/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hive/lib/scalap-2.11.0.jar:/opt/hive/lib/sketches-core-0.9.0.jar:/opt/hive/lib/snappy-java-1.1.4.jar:/opt/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hive/lib/sqlline-1.3.0.jar:/opt/hive/lib/stax-api-1.0.1.jar:/opt/hive/lib/stream-2.7.0.jar:/opt/hive/lib/super-csv-2.2.0.jar:/opt/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hive/lib/tempus-fugit-1.1.jar:/opt/hive/lib/threetenbp-1.3.5.jar:/opt/hive/lib/transaction-api-1.1.jar:/opt/hive/lib/unused-1.0.0.jar:/opt/hive/lib/validation-api-1.1.0.Final.jar:/opt/hive/lib/velocity-1.7.jar:/opt/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hive/lib/xz-1.5.jar:/opt/hive/lib/zookeeper-3.4.6.jar:/opt/hive/lib/zstd-jni-1.3.2-2.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.1.0.jar:/opt/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hive/lib/log4j-api-2.17.1.jar:/opt/hive/lib/log4j-core-2.17.1.jar:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar
STARTUP_MSG:   build = git://MacBook-Pro.fios-router.home/Users/ngangam/commit/hive -r 4df4d75bf1e16fe0af75aad0b4179c34c07fc975; compiled by 'ngangam' on Sun Apr 3 16:58:33 EDT 2022
************************************************************/
2025-08-03T14:18:48,316  INFO [main] metastore.HiveMetaStore: Starting hive metastore on port 9083
2025-08-03T14:18:48,563  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T14:18:48,662  WARN [main] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T14:18:48,670  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T14:18:48,672  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T14:18:48,672  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:18:48,673  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T14:18:48,673  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:18:49,192  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2025-08-03T14:18:49,516  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2025-08-03T14:18:49,566  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2025-08-03T14:18:49,611  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2025-08-03T14:18:49,792  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-03T14:18:49,946  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T14:18:49,949  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T14:18:52,876  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2025-08-03T14:18:52,879  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2025-08-03T14:18:52,901  INFO [main] metastore.HiveMetaStore: No user is added in admin role, since config is empty
2025-08-03T14:18:52,997  INFO [main] conf.HiveConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T14:18:53,225  INFO [main] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2025-08-03T14:18:53,231  INFO [main] metastore.HiveMetaStore: Started the new metaserver on port [9083]...
2025-08-03T14:18:53,231  INFO [main] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2025-08-03T14:18:53,231  INFO [main] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2025-08-03T14:18:53,231  INFO [main] metastore.HiveMetaStore: TCP keepalive = true
2025-08-03T14:18:53,231  INFO [main] metastore.HiveMetaStore: Enable SSL = false
2025-08-03T14:50:08,523  INFO [pool-2-thread-1] metastore.HiveMetaStore: Shutting down hive metastore.
2025-08-03T14:50:08,527  INFO [pool-2-thread-1] metastore.HiveMetaStore: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down HiveMetaStore at 086139701e19/172.18.0.4
************************************************************/
2025-08-03T14:50:51,585  INFO [main] conf.MetastoreConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T14:50:52,010  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T14:50:52,011  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:50:52,011  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T14:50:52,012  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:50:52,088  INFO [main] metastore.HiveMetaStore: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting HiveMetaStore
STARTUP_MSG:   host = 561623cd1110/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.3
STARTUP_MSG:   classpath = /opt/hive/conf:/opt/hive/lib/HikariCP-2.6.1.jar:/opt/hive/lib/JavaEWAH-0.3.2.jar:/opt/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hive/lib/ST4-4.0.4.jar:/opt/hive/lib/accumulo-core-1.7.3.jar:/opt/hive/lib/accumulo-fate-1.7.3.jar:/opt/hive/lib/accumulo-start-1.7.3.jar:/opt/hive/lib/accumulo-trace-1.7.3.jar:/opt/hive/lib/aircompressor-0.10.jar:/opt/hive/lib/ant-1.9.1.jar:/opt/hive/lib/ant-launcher-1.9.1.jar:/opt/hive/lib/antlr-runtime-3.5.2.jar:/opt/hive/lib/antlr4-runtime-4.5.jar:/opt/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hive/lib/arrow-format-0.8.0.jar:/opt/hive/lib/arrow-memory-0.8.0.jar:/opt/hive/lib/arrow-vector-0.8.0.jar:/opt/hive/lib/asm-5.0.1.jar:/opt/hive/lib/asm-commons-5.0.1.jar:/opt/hive/lib/asm-tree-5.0.1.jar:/opt/hive/lib/audience-annotations-0.5.0.jar:/opt/hive/lib/avatica-1.11.0.jar:/opt/hive/lib/avro-1.8.2.jar:/opt/hive/lib/avro-ipc-1.8.2.jar:/opt/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.375.jar:/opt/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hive/lib/calcite-core-1.16.0.jar:/opt/hive/lib/calcite-druid-1.16.0.jar:/opt/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hive/lib/chill-java-0.8.4.jar:/opt/hive/lib/chill_2.11-0.8.4.jar:/opt/hive/lib/commons-cli-1.2.jar:/opt/hive/lib/commons-codec-1.15.jar:/opt/hive/lib/commons-collections4-4.1.jar:/opt/hive/lib/commons-compiler-2.7.6.jar:/opt/hive/lib/commons-compress-1.19.jar:/opt/hive/lib/commons-crypto-1.0.0.jar:/opt/hive/lib/commons-dbcp-1.4.jar:/opt/hive/lib/commons-io-2.6.jar:/opt/hive/lib/commons-lang-2.6.jar:/opt/hive/lib/commons-lang3-3.9.jar:/opt/hive/lib/commons-logging-1.0.4.jar:/opt/hive/lib/commons-math-2.1.jar:/opt/hive/lib/commons-math3-3.6.1.jar:/opt/hive/lib/commons-pool-1.5.4.jar:/opt/hive/lib/commons-vfs2-2.1.jar:/opt/hive/lib/compress-lzf-1.0.3.jar:/opt/hive/lib/curator-client-2.12.0.jar:/opt/hive/lib/curator-framework-2.12.0.jar:/opt/hive/lib/curator-recipes-2.12.0.jar:/opt/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hive/lib/datanucleus-core-4.1.17.jar:/opt/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hive/lib/derby-10.14.1.0.jar:/opt/hive/lib/disruptor-3.3.6.jar:/opt/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hive/lib/ecj-4.4.2.jar:/opt/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hive/lib/groovy-all-2.4.11.jar:/opt/hive/lib/gson-2.2.4.jar:/opt/hive/lib/guava-19.0.jar:/opt/hive/lib/hadoop-aws-3.1.2.jar:/opt/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hive/lib/hive-beeline-3.1.3.jar:/opt/hive/lib/hive-classification-3.1.3.jar:/opt/hive/lib/hive-cli-3.1.3.jar:/opt/hive/lib/hive-common-3.1.3.jar:/opt/hive/lib/hive-contrib-3.1.3.jar:/opt/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hive/lib/hive-exec-3.1.3.jar:/opt/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hive/lib/hive-hplsql-3.1.3.jar:/opt/hive/lib/hive-jdbc-3.1.3.jar:/opt/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hive/lib/hive-llap-client-3.1.3.jar:/opt/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hive/lib/hive-llap-common-3.1.3.jar:/opt/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hive/lib/hive-llap-server-3.1.3.jar:/opt/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hive/lib/hive-metastore-3.1.3.jar:/opt/hive/lib/hive-serde-3.1.3.jar:/opt/hive/lib/hive-service-3.1.3.jar:/opt/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hive/lib/hive-shims-3.1.3.jar:/opt/hive/lib/hive-shims-common-3.1.3.jar:/opt/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hive/lib/hive-spark-client-3.1.3.jar:/opt/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hive/lib/hive-storage-api-2.7.0.jar:/opt/hive/lib/hive-streaming-3.1.3.jar:/opt/hive/lib/hive-testutils-3.1.3.jar:/opt/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hive/lib/hppc-0.7.2.jar:/opt/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hive/lib/httpclient-4.5.13.jar:/opt/hive/lib/httpcore-4.4.13.jar:/opt/hive/lib/ivy-2.4.0.jar:/opt/hive/lib/jackson-annotations-2.12.0.jar:/opt/hive/lib/jackson-core-2.12.0.jar:/opt/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hive/lib/jackson-databind-2.12.0.jar:/opt/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hive/lib/jamon-runtime-2.3.1.jar:/opt/hive/lib/janino-2.7.6.jar:/opt/hive/lib/javassist-3.20.0-GA.jar:/opt/hive/lib/javax.annotation-api-1.2.jar:/opt/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hive/lib/javolution-5.5.1.jar:/opt/hive/lib/jaxb-api-2.2.11.jar:/opt/hive/lib/jcodings-1.0.18.jar:/opt/hive/lib/jcommander-1.32.jar:/opt/hive/lib/jdo-api-3.0.1.jar:/opt/hive/lib/jersey-client-2.25.1.jar:/opt/hive/lib/jersey-common-2.25.1.jar:/opt/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hive/lib/jersey-guava-2.25.1.jar:/opt/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hive/lib/jersey-server-2.25.1.jar:/opt/hive/lib/jettison-1.1.jar:/opt/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hive/lib/jetty-schemas-3.1.jar:/opt/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hive/lib/jline-2.12.jar:/opt/hive/lib/joda-time-2.9.9.jar:/opt/hive/lib/jodd-core-3.5.2.jar:/opt/hive/lib/joni-2.1.11.jar:/opt/hive/lib/jpam-1.1.jar:/opt/hive/lib/json-1.8.jar:/opt/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hive/lib/jsr305-3.0.0.jar:/opt/hive/lib/jta-1.1.jar:/opt/hive/lib/kryo-shaded-3.0.3.jar:/opt/hive/lib/libfb303-0.9.3.jar:/opt/hive/lib/libthrift-0.9.3.jar:/opt/hive/lib/lz4-java-1.4.0.jar:/opt/hive/lib/memory-0.9.0.jar:/opt/hive/lib/metrics-core-3.1.0.jar:/opt/hive/lib/metrics-graphite-3.1.5.jar:/opt/hive/lib/metrics-json-3.1.0.jar:/opt/hive/lib/metrics-jvm-3.1.0.jar:/opt/hive/lib/minlog-1.3.0.jar:/opt/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hive/lib/netty-3.10.5.Final.jar:/opt/hive/lib/netty-all-4.1.17.Final.jar:/opt/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hive/lib/netty-common-4.1.17.Final.jar:/opt/hive/lib/objenesis-2.1.jar:/opt/hive/lib/opencsv-2.3.jar:/opt/hive/lib/opencsv-3.9.jar:/opt/hive/lib/orc-core-1.5.8.jar:/opt/hive/lib/orc-shims-1.5.8.jar:/opt/hive/lib/orc-tools-1.5.8.jar:/opt/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hive/lib/paranamer-2.7.jar:/opt/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hive/lib/postgresql-42.7.7.jar:/opt/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hive/lib/protobuf-java-2.5.0.jar:/opt/hive/lib/py4j-0.10.6.jar:/opt/hive/lib/pyrolite-4.13.jar:/opt/hive/lib/scala-compiler-2.11.0.jar:/opt/hive/lib/scala-library-2.11.8.jar:/opt/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hive/lib/scala-reflect-2.11.0.jar:/opt/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hive/lib/scalap-2.11.0.jar:/opt/hive/lib/sketches-core-0.9.0.jar:/opt/hive/lib/snappy-java-1.1.4.jar:/opt/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hive/lib/sqlline-1.3.0.jar:/opt/hive/lib/stax-api-1.0.1.jar:/opt/hive/lib/stream-2.7.0.jar:/opt/hive/lib/super-csv-2.2.0.jar:/opt/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hive/lib/tempus-fugit-1.1.jar:/opt/hive/lib/threetenbp-1.3.5.jar:/opt/hive/lib/transaction-api-1.1.jar:/opt/hive/lib/unused-1.0.0.jar:/opt/hive/lib/validation-api-1.1.0.Final.jar:/opt/hive/lib/velocity-1.7.jar:/opt/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hive/lib/xz-1.5.jar:/opt/hive/lib/zookeeper-3.4.6.jar:/opt/hive/lib/zstd-jni-1.3.2-2.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.1.0.jar:/opt/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hive/lib/log4j-api-2.17.1.jar:/opt/hive/lib/log4j-core-2.17.1.jar:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar
STARTUP_MSG:   build = git://MacBook-Pro.fios-router.home/Users/ngangam/commit/hive -r 4df4d75bf1e16fe0af75aad0b4179c34c07fc975; compiled by 'ngangam' on Sun Apr 3 16:58:33 EDT 2022
************************************************************/
2025-08-03T14:50:52,136  INFO [main] metastore.HiveMetaStore: Starting hive metastore on port 9083
2025-08-03T14:50:52,316  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T14:50:52,449  WARN [main] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T14:50:52,461  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T14:50:52,463  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T14:50:52,463  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:50:52,464  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T14:50:52,464  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T14:50:53,122  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2025-08-03T14:50:53,570  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2025-08-03T14:50:53,629  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2025-08-03T14:50:53,671  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2025-08-03T14:50:53,885  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-03T14:50:54,066  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T14:50:54,069  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T14:50:56,820  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2025-08-03T14:50:56,824  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2025-08-03T14:50:56,848  INFO [main] metastore.HiveMetaStore: No user is added in admin role, since config is empty
2025-08-03T14:50:56,937  INFO [main] conf.HiveConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T14:50:57,142  INFO [main] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2025-08-03T14:50:57,147  INFO [main] metastore.HiveMetaStore: Started the new metaserver on port [9083]...
2025-08-03T14:50:57,148  INFO [main] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2025-08-03T14:50:57,148  INFO [main] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2025-08-03T14:50:57,148  INFO [main] metastore.HiveMetaStore: TCP keepalive = true
2025-08-03T14:50:57,148  INFO [main] metastore.HiveMetaStore: Enable SSL = false
2025-08-03T15:15:45,439  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: default
2025-08-03T15:15:45,449  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T15:15:45,455  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T15:15:45,458  WARN [pool-6-thread-1] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T15:15:45,461  INFO [pool-6-thread-1] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T15:15:45,616  INFO [pool-6-thread-1] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T15:15:45,616  INFO [pool-6-thread-1] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T15:15:45,638  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:15:45,639  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:15:45,642  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:15:45,655  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:15:45,655  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:15:45,658  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:15:45,666  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: global_temp
2025-08-03T15:15:45,666  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T15:15:45,670  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T15:15:45,695  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T15:15:45,696  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T15:15:45,700  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:15:46,427 ERROR [pool-6-thread-1] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T15:15:47,607  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:15:47,608  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:15:47,635  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:20:40,374  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:20:40,377  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:20:40,386  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:20:40,390  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:20:40,390  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:20:40,394  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:20:40,399  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:file:/opt/spark-data/smartlogistics, parameters:{}, ownerName:spark)
2025-08-03T15:20:40,399  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:file:/opt/spark-data/smartlogistics, parameters:{}, ownerName:spark)	
2025-08-03T15:20:40,403  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:20:40,477  INFO [pool-6-thread-1] utils.FileUtils: Creating directory if it doesn't exist: file:/opt/spark-data/smartlogistics
2025-08-03T15:20:40,556 ERROR [pool-6-thread-1] metastore.RetryingHMSHandler: MetaException(message:Unable to create database path file:/opt/spark-data/smartlogistics, failed to create database smartlogistics)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1267)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2025-08-03T15:26:36,817  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Cleaning up thread local RawStore...
2025-08-03T15:26:36,818  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T15:26:36,822  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Done cleaning up thread local RawStore
2025-08-03T15:26:36,823  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T15:37:54,351  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: default
2025-08-03T15:37:54,353  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T15:37:54,356  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T15:37:54,357  WARN [pool-6-thread-2] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T15:37:54,359  INFO [pool-6-thread-2] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T15:37:54,401  INFO [pool-6-thread-2] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T15:37:54,402  INFO [pool-6-thread-2] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T15:37:54,429  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:37:54,430  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:37:54,435  WARN [pool-6-thread-2] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:37:54,441  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:37:54,442  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:37:54,446  WARN [pool-6-thread-2] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:37:54,457  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: global_temp
2025-08-03T15:37:54,457  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T15:37:54,464  WARN [pool-6-thread-2] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T15:37:54,481  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T15:37:54,481  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T15:37:54,485  WARN [pool-6-thread-2] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:37:54,497 ERROR [pool-6-thread-2] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T15:39:16,740  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: Cleaning up thread local RawStore...
2025-08-03T15:39:16,740  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T15:39:16,741  INFO [pool-6-thread-2] metastore.HiveMetaStore: 2: Done cleaning up thread local RawStore
2025-08-03T15:39:16,741  INFO [pool-6-thread-2] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T15:51:11,594  INFO [pool-4-thread-1] metastore.HiveMetaStore: 3: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T15:51:11,596  WARN [pool-4-thread-1] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T15:51:11,597  INFO [pool-4-thread-1] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T15:51:11,625  INFO [pool-4-thread-1] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T15:51:11,626  INFO [pool-4-thread-1] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T15:51:21,546  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: default
2025-08-03T15:51:21,547  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T15:51:21,551  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T15:51:21,552  INFO [pool-6-thread-3] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T15:51:21,563  INFO [pool-6-thread-3] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T15:51:21,563  INFO [pool-6-thread-3] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T15:51:21,583  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:51:21,583  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:51:21,588  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:51:21,595  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:51:21,595  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:51:21,600  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:51:21,613  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: global_temp
2025-08-03T15:51:21,614  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T15:51:21,618  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T15:51:21,633  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T15:51:21,634  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T15:51:21,638  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:51:21,651 ERROR [pool-6-thread-3] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T15:53:27,388  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: Cleaning up thread local RawStore...
2025-08-03T15:53:27,389  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T15:53:27,390  INFO [pool-6-thread-3] metastore.HiveMetaStore: 4: Done cleaning up thread local RawStore
2025-08-03T15:53:27,390  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T15:56:01,914  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: source:172.18.0.6 get_database: default
2025-08-03T15:56:01,915  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T15:56:01,919  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T15:56:01,920  INFO [pool-6-thread-4] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T15:56:01,932  INFO [pool-6-thread-4] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T15:56:01,932  INFO [pool-6-thread-4] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T15:56:01,947  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:56:01,949  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:56:01,954  WARN [pool-6-thread-4] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:56:01,960  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: source:172.18.0.6 get_database: smartlogistics
2025-08-03T15:56:01,961  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T15:56:01,967  WARN [pool-6-thread-4] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:56:01,978  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: source:172.18.0.6 get_database: global_temp
2025-08-03T15:56:01,979  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T15:56:01,984  WARN [pool-6-thread-4] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T15:56:01,996  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T15:56:01,997  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T15:56:02,002  WARN [pool-6-thread-4] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T15:56:02,023 ERROR [pool-6-thread-4] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T15:58:56,767  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: Cleaning up thread local RawStore...
2025-08-03T15:58:56,767  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T15:58:56,768  INFO [pool-6-thread-4] metastore.HiveMetaStore: 5: Done cleaning up thread local RawStore
2025-08-03T15:58:56,768  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:00:03,597  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: source:172.18.0.6 get_database: default
2025-08-03T16:00:03,598  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T16:00:03,602  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:00:03,603  INFO [pool-6-thread-5] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:00:03,617  INFO [pool-6-thread-5] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:00:03,617  INFO [pool-6-thread-5] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:00:03,630  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:00:03,630  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:00:03,634  WARN [pool-6-thread-5] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:00:03,639  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:00:03,640  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:00:03,644  WARN [pool-6-thread-5] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:00:03,653  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: source:172.18.0.6 get_database: global_temp
2025-08-03T16:00:03,653  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T16:00:03,657  WARN [pool-6-thread-5] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T16:00:03,669  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T16:00:03,670  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T16:00:03,675  WARN [pool-6-thread-5] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:00:03,686 ERROR [pool-6-thread-5] metastore.RetryingHMSHandler: MetaException(message:java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.newMetaException(HiveMetaStore.java:6937)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1338)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2592)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	... 20 more
Caused by: java.lang.ClassNotFoundException: Class org.apache.hadoop.fs.s3a.S3AFileSystem not found
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2496)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	... 33 more

2025-08-03T16:03:25,072  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: Cleaning up thread local RawStore...
2025-08-03T16:03:25,073  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:03:25,074  INFO [pool-6-thread-5] metastore.HiveMetaStore: 6: Done cleaning up thread local RawStore
2025-08-03T16:03:25,074  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:03:37,293  INFO [pool-2-thread-1] metastore.HiveMetaStore: Shutting down hive metastore.
2025-08-03T16:03:37,297  INFO [pool-2-thread-1] metastore.HiveMetaStore: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down HiveMetaStore at 561623cd1110/172.18.0.3
************************************************************/
2025-08-03T16:03:43,906  INFO [main] conf.MetastoreConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T16:03:44,415  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T16:03:44,416  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:03:44,418  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T16:03:44,418  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:03:44,527  INFO [main] metastore.HiveMetaStore: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting HiveMetaStore
STARTUP_MSG:   host = 561623cd1110/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.3
STARTUP_MSG:   classpath = /opt/hive/conf:/opt/hive/lib/HikariCP-2.6.1.jar:/opt/hive/lib/JavaEWAH-0.3.2.jar:/opt/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hive/lib/ST4-4.0.4.jar:/opt/hive/lib/accumulo-core-1.7.3.jar:/opt/hive/lib/accumulo-fate-1.7.3.jar:/opt/hive/lib/accumulo-start-1.7.3.jar:/opt/hive/lib/accumulo-trace-1.7.3.jar:/opt/hive/lib/aircompressor-0.10.jar:/opt/hive/lib/ant-1.9.1.jar:/opt/hive/lib/ant-launcher-1.9.1.jar:/opt/hive/lib/antlr-runtime-3.5.2.jar:/opt/hive/lib/antlr4-runtime-4.5.jar:/opt/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hive/lib/arrow-format-0.8.0.jar:/opt/hive/lib/arrow-memory-0.8.0.jar:/opt/hive/lib/arrow-vector-0.8.0.jar:/opt/hive/lib/asm-5.0.1.jar:/opt/hive/lib/asm-commons-5.0.1.jar:/opt/hive/lib/asm-tree-5.0.1.jar:/opt/hive/lib/audience-annotations-0.5.0.jar:/opt/hive/lib/avatica-1.11.0.jar:/opt/hive/lib/avro-1.8.2.jar:/opt/hive/lib/avro-ipc-1.8.2.jar:/opt/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.375.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.901.jar:/opt/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hive/lib/calcite-core-1.16.0.jar:/opt/hive/lib/calcite-druid-1.16.0.jar:/opt/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hive/lib/chill-java-0.8.4.jar:/opt/hive/lib/chill_2.11-0.8.4.jar:/opt/hive/lib/commons-cli-1.2.jar:/opt/hive/lib/commons-codec-1.15.jar:/opt/hive/lib/commons-collections4-4.1.jar:/opt/hive/lib/commons-compiler-2.7.6.jar:/opt/hive/lib/commons-compress-1.19.jar:/opt/hive/lib/commons-crypto-1.0.0.jar:/opt/hive/lib/commons-dbcp-1.4.jar:/opt/hive/lib/commons-io-2.6.jar:/opt/hive/lib/commons-lang-2.6.jar:/opt/hive/lib/commons-lang3-3.9.jar:/opt/hive/lib/commons-logging-1.0.4.jar:/opt/hive/lib/commons-math-2.1.jar:/opt/hive/lib/commons-math3-3.6.1.jar:/opt/hive/lib/commons-pool-1.5.4.jar:/opt/hive/lib/commons-vfs2-2.1.jar:/opt/hive/lib/compress-lzf-1.0.3.jar:/opt/hive/lib/curator-client-2.12.0.jar:/opt/hive/lib/curator-framework-2.12.0.jar:/opt/hive/lib/curator-recipes-2.12.0.jar:/opt/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hive/lib/datanucleus-core-4.1.17.jar:/opt/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hive/lib/derby-10.14.1.0.jar:/opt/hive/lib/disruptor-3.3.6.jar:/opt/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hive/lib/ecj-4.4.2.jar:/opt/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hive/lib/groovy-all-2.4.11.jar:/opt/hive/lib/gson-2.2.4.jar:/opt/hive/lib/guava-19.0.jar:/opt/hive/lib/hadoop-aws-3.1.2.jar:/opt/hive/lib/hadoop-aws-3.3.1.jar:/opt/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hive/lib/hive-beeline-3.1.3.jar:/opt/hive/lib/hive-classification-3.1.3.jar:/opt/hive/lib/hive-cli-3.1.3.jar:/opt/hive/lib/hive-common-3.1.3.jar:/opt/hive/lib/hive-contrib-3.1.3.jar:/opt/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hive/lib/hive-exec-3.1.3.jar:/opt/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hive/lib/hive-hplsql-3.1.3.jar:/opt/hive/lib/hive-jdbc-3.1.3.jar:/opt/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hive/lib/hive-llap-client-3.1.3.jar:/opt/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hive/lib/hive-llap-common-3.1.3.jar:/opt/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hive/lib/hive-llap-server-3.1.3.jar:/opt/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hive/lib/hive-metastore-3.1.3.jar:/opt/hive/lib/hive-serde-3.1.3.jar:/opt/hive/lib/hive-service-3.1.3.jar:/opt/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hive/lib/hive-shims-3.1.3.jar:/opt/hive/lib/hive-shims-common-3.1.3.jar:/opt/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hive/lib/hive-spark-client-3.1.3.jar:/opt/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hive/lib/hive-storage-api-2.7.0.jar:/opt/hive/lib/hive-streaming-3.1.3.jar:/opt/hive/lib/hive-testutils-3.1.3.jar:/opt/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hive/lib/hppc-0.7.2.jar:/opt/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hive/lib/httpclient-4.5.13.jar:/opt/hive/lib/httpcore-4.4.13.jar:/opt/hive/lib/ivy-2.4.0.jar:/opt/hive/lib/jackson-annotations-2.12.0.jar:/opt/hive/lib/jackson-core-2.12.0.jar:/opt/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hive/lib/jackson-databind-2.12.0.jar:/opt/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hive/lib/jamon-runtime-2.3.1.jar:/opt/hive/lib/janino-2.7.6.jar:/opt/hive/lib/javassist-3.20.0-GA.jar:/opt/hive/lib/javax.annotation-api-1.2.jar:/opt/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hive/lib/javolution-5.5.1.jar:/opt/hive/lib/jaxb-api-2.2.11.jar:/opt/hive/lib/jcodings-1.0.18.jar:/opt/hive/lib/jcommander-1.32.jar:/opt/hive/lib/jdo-api-3.0.1.jar:/opt/hive/lib/jersey-client-2.25.1.jar:/opt/hive/lib/jersey-common-2.25.1.jar:/opt/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hive/lib/jersey-guava-2.25.1.jar:/opt/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hive/lib/jersey-server-2.25.1.jar:/opt/hive/lib/jettison-1.1.jar:/opt/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hive/lib/jetty-schemas-3.1.jar:/opt/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hive/lib/jline-2.12.jar:/opt/hive/lib/joda-time-2.9.9.jar:/opt/hive/lib/jodd-core-3.5.2.jar:/opt/hive/lib/joni-2.1.11.jar:/opt/hive/lib/jpam-1.1.jar:/opt/hive/lib/json-1.8.jar:/opt/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hive/lib/jsr305-3.0.0.jar:/opt/hive/lib/jta-1.1.jar:/opt/hive/lib/kryo-shaded-3.0.3.jar:/opt/hive/lib/libfb303-0.9.3.jar:/opt/hive/lib/libthrift-0.9.3.jar:/opt/hive/lib/lz4-java-1.4.0.jar:/opt/hive/lib/memory-0.9.0.jar:/opt/hive/lib/metrics-core-3.1.0.jar:/opt/hive/lib/metrics-graphite-3.1.5.jar:/opt/hive/lib/metrics-json-3.1.0.jar:/opt/hive/lib/metrics-jvm-3.1.0.jar:/opt/hive/lib/minlog-1.3.0.jar:/opt/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hive/lib/netty-3.10.5.Final.jar:/opt/hive/lib/netty-all-4.1.17.Final.jar:/opt/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hive/lib/netty-common-4.1.17.Final.jar:/opt/hive/lib/objenesis-2.1.jar:/opt/hive/lib/opencsv-2.3.jar:/opt/hive/lib/opencsv-3.9.jar:/opt/hive/lib/orc-core-1.5.8.jar:/opt/hive/lib/orc-shims-1.5.8.jar:/opt/hive/lib/orc-tools-1.5.8.jar:/opt/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hive/lib/paranamer-2.7.jar:/opt/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hive/lib/postgresql-42.7.7.jar:/opt/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hive/lib/protobuf-java-2.5.0.jar:/opt/hive/lib/py4j-0.10.6.jar:/opt/hive/lib/pyrolite-4.13.jar:/opt/hive/lib/scala-compiler-2.11.0.jar:/opt/hive/lib/scala-library-2.11.8.jar:/opt/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hive/lib/scala-reflect-2.11.0.jar:/opt/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hive/lib/scalap-2.11.0.jar:/opt/hive/lib/sketches-core-0.9.0.jar:/opt/hive/lib/snappy-java-1.1.4.jar:/opt/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hive/lib/sqlline-1.3.0.jar:/opt/hive/lib/stax-api-1.0.1.jar:/opt/hive/lib/stream-2.7.0.jar:/opt/hive/lib/super-csv-2.2.0.jar:/opt/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hive/lib/tempus-fugit-1.1.jar:/opt/hive/lib/threetenbp-1.3.5.jar:/opt/hive/lib/transaction-api-1.1.jar:/opt/hive/lib/unused-1.0.0.jar:/opt/hive/lib/validation-api-1.1.0.Final.jar:/opt/hive/lib/velocity-1.7.jar:/opt/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hive/lib/xz-1.5.jar:/opt/hive/lib/zookeeper-3.4.6.jar:/opt/hive/lib/zstd-jni-1.3.2-2.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.1.0.jar:/opt/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hive/lib/log4j-api-2.17.1.jar:/opt/hive/lib/log4j-core-2.17.1.jar:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar
STARTUP_MSG:   build = git://MacBook-Pro.fios-router.home/Users/ngangam/commit/hive -r 4df4d75bf1e16fe0af75aad0b4179c34c07fc975; compiled by 'ngangam' on Sun Apr 3 16:58:33 EDT 2022
************************************************************/
2025-08-03T16:03:44,619  INFO [main] metastore.HiveMetaStore: Starting hive metastore on port 9083
2025-08-03T16:03:44,981  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:03:45,108  WARN [main] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:03:45,121  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:03:45,123  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T16:03:45,123  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:03:45,124  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T16:03:45,124  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:03:45,865  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2025-08-03T16:03:46,348  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2025-08-03T16:03:46,421  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2025-08-03T16:03:46,485  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2025-08-03T16:03:46,654  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-03T16:03:46,824  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:03:46,826  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:03:50,495  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2025-08-03T16:03:50,499  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2025-08-03T16:03:50,538  INFO [main] metastore.HiveMetaStore: No user is added in admin role, since config is empty
2025-08-03T16:03:50,693  INFO [main] conf.HiveConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T16:03:51,209  INFO [main] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2025-08-03T16:03:51,218  INFO [main] metastore.HiveMetaStore: Started the new metaserver on port [9083]...
2025-08-03T16:03:51,218  INFO [main] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2025-08-03T16:03:51,218  INFO [main] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2025-08-03T16:03:51,219  INFO [main] metastore.HiveMetaStore: TCP keepalive = true
2025-08-03T16:03:51,219  INFO [main] metastore.HiveMetaStore: Enable SSL = false
2025-08-03T16:04:49,159  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: default
2025-08-03T16:04:49,163  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T16:04:49,165  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:04:49,166  WARN [pool-6-thread-1] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:04:49,166  INFO [pool-6-thread-1] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:04:49,184  INFO [pool-6-thread-1] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:04:49,184  INFO [pool-6-thread-1] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:04:49,203  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:04:49,204  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:04:49,207  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:04:49,217  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:04:49,218  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:04:49,221  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:04:49,229  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: global_temp
2025-08-03T16:04:49,230  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T16:04:49,233  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T16:04:49,258  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T16:04:49,258  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T16:04:49,264  WARN [pool-6-thread-1] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:04:49,878 ERROR [pool-6-thread-1] metastore.RetryingHMSHandler: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/statistics/IOStatisticsSource
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:405)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2529)
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2494)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.statistics.IOStatisticsSource
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 51 more

2025-08-03T16:04:49,879  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Cleaning up thread local RawStore...
2025-08-03T16:04:49,879  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:04:49,880  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Done cleaning up thread local RawStore
2025-08-03T16:04:49,880  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:04:50,898  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T16:04:50,899  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T16:04:50,902  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:04:50,902  WARN [pool-6-thread-3] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:04:50,903  INFO [pool-6-thread-3] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:04:50,912  INFO [pool-6-thread-3] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:04:50,912  INFO [pool-6-thread-3] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:04:50,915  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:04:50,932 ERROR [pool-6-thread-3] metastore.RetryingHMSHandler: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/statistics/IOStatisticsSource
	at java.lang.ClassLoader.defineClass1(Native Method)
	at java.lang.ClassLoader.defineClass(ClassLoader.java:756)
	at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)
	at java.net.URLClassLoader.defineClass(URLClassLoader.java:473)
	at java.net.URLClassLoader.access$100(URLClassLoader.java:74)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:369)
	at java.net.URLClassLoader$1.run(URLClassLoader.java:363)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:362)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:405)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.hadoop.conf.Configuration.getClassByNameOrNull(Configuration.java:2529)
	at org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:2494)
	at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2590)
	at org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3320)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3352)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:124)
	at org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3403)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3371)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:477)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:361)
	at org.apache.hadoop.hive.metastore.Warehouse.getFs(Warehouse.java:115)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:141)
	at org.apache.hadoop.hive.metastore.Warehouse.getDnsPath(Warehouse.java:147)
	at org.apache.hadoop.hive.metastore.Warehouse.determineDatabasePath(Warehouse.java:190)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database_core(HiveMetaStore.java:1255)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.create_database(HiveMetaStore.java:1327)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.create_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14396)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$create_database.getResult(ThriftHiveMetastore.java:14380)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1682)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)
Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.statistics.IOStatisticsSource
	at java.net.URLClassLoader.findClass(URLClassLoader.java:387)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:418)
	at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:352)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:351)
	... 51 more

2025-08-03T16:04:50,932  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Cleaning up thread local RawStore...
2025-08-03T16:04:50,932  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:04:50,933  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Done cleaning up thread local RawStore
2025-08-03T16:04:50,933  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:07:44,690  INFO [pool-2-thread-1] metastore.HiveMetaStore: Shutting down hive metastore.
2025-08-03T16:07:44,693  INFO [pool-2-thread-1] metastore.HiveMetaStore: SHUTDOWN_MSG: 
/************************************************************
SHUTDOWN_MSG: Shutting down HiveMetaStore at 561623cd1110/172.18.0.3
************************************************************/
2025-08-03T16:12:16,682  INFO [main] conf.MetastoreConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T16:12:16,782  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T16:12:16,783  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:12:16,784  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T16:12:16,784  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:12:16,863  INFO [main] metastore.HiveMetaStore: STARTUP_MSG: 
/************************************************************
STARTUP_MSG: Starting HiveMetaStore
STARTUP_MSG:   host = 561623cd1110/172.18.0.3
STARTUP_MSG:   args = []
STARTUP_MSG:   version = 3.1.3
STARTUP_MSG:   classpath = /opt/hive/conf:/opt/hive/lib/HikariCP-2.6.1.jar:/opt/hive/lib/JavaEWAH-0.3.2.jar:/opt/hive/lib/RoaringBitmap-0.5.11.jar:/opt/hive/lib/ST4-4.0.4.jar:/opt/hive/lib/accumulo-core-1.7.3.jar:/opt/hive/lib/accumulo-fate-1.7.3.jar:/opt/hive/lib/accumulo-start-1.7.3.jar:/opt/hive/lib/accumulo-trace-1.7.3.jar:/opt/hive/lib/aircompressor-0.10.jar:/opt/hive/lib/ant-1.9.1.jar:/opt/hive/lib/ant-launcher-1.9.1.jar:/opt/hive/lib/antlr-runtime-3.5.2.jar:/opt/hive/lib/antlr4-runtime-4.5.jar:/opt/hive/lib/aopalliance-repackaged-2.5.0-b32.jar:/opt/hive/lib/apache-jsp-9.3.20.v20170531.jar:/opt/hive/lib/apache-jstl-9.3.20.v20170531.jar:/opt/hive/lib/arrow-format-0.8.0.jar:/opt/hive/lib/arrow-memory-0.8.0.jar:/opt/hive/lib/arrow-vector-0.8.0.jar:/opt/hive/lib/asm-5.0.1.jar:/opt/hive/lib/asm-commons-5.0.1.jar:/opt/hive/lib/asm-tree-5.0.1.jar:/opt/hive/lib/audience-annotations-0.5.0.jar:/opt/hive/lib/avatica-1.11.0.jar:/opt/hive/lib/avro-1.8.2.jar:/opt/hive/lib/avro-ipc-1.8.2.jar:/opt/hive/lib/avro-mapred-1.8.2-hadoop2.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.375.jar:/opt/hive/lib/aws-java-sdk-bundle-1.11.901.jar:/opt/hive/lib/bonecp-0.8.0.RELEASE.jar:/opt/hive/lib/calcite-core-1.16.0.jar:/opt/hive/lib/calcite-druid-1.16.0.jar:/opt/hive/lib/calcite-linq4j-1.16.0.jar:/opt/hive/lib/chill-java-0.8.4.jar:/opt/hive/lib/chill_2.11-0.8.4.jar:/opt/hive/lib/commons-cli-1.2.jar:/opt/hive/lib/commons-codec-1.15.jar:/opt/hive/lib/commons-collections4-4.1.jar:/opt/hive/lib/commons-compiler-2.7.6.jar:/opt/hive/lib/commons-compress-1.19.jar:/opt/hive/lib/commons-crypto-1.0.0.jar:/opt/hive/lib/commons-dbcp-1.4.jar:/opt/hive/lib/commons-io-2.6.jar:/opt/hive/lib/commons-lang-2.6.jar:/opt/hive/lib/commons-lang3-3.9.jar:/opt/hive/lib/commons-logging-1.0.4.jar:/opt/hive/lib/commons-math-2.1.jar:/opt/hive/lib/commons-math3-3.6.1.jar:/opt/hive/lib/commons-pool-1.5.4.jar:/opt/hive/lib/commons-vfs2-2.1.jar:/opt/hive/lib/compress-lzf-1.0.3.jar:/opt/hive/lib/curator-client-2.12.0.jar:/opt/hive/lib/curator-framework-2.12.0.jar:/opt/hive/lib/curator-recipes-2.12.0.jar:/opt/hive/lib/datanucleus-api-jdo-4.2.4.jar:/opt/hive/lib/datanucleus-core-4.1.17.jar:/opt/hive/lib/datanucleus-rdbms-4.1.19.jar:/opt/hive/lib/derby-10.14.1.0.jar:/opt/hive/lib/disruptor-3.3.6.jar:/opt/hive/lib/dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar:/opt/hive/lib/druid-hdfs-storage-0.12.0.jar:/opt/hive/lib/ecj-4.4.2.jar:/opt/hive/lib/esri-geometry-api-2.0.0.jar:/opt/hive/lib/findbugs-annotations-1.3.9-1.jar:/opt/hive/lib/flatbuffers-1.2.0-3f79e055.jar:/opt/hive/lib/groovy-all-2.4.11.jar:/opt/hive/lib/gson-2.2.4.jar:/opt/hive/lib/guava-19.0.jar:/opt/hive/lib/hadoop-aws-3.1.2.jar:/opt/hive/lib/hadoop-aws-3.3.1.jar:/opt/hive/lib/hadoop-common-3.3.1.jar:/opt/hive/lib/hadoop-shaded-guava-1.1.1.jar:/opt/hive/lib/hbase-client-2.0.0-alpha4.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-common-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4-tests.jar:/opt/hive/lib/hbase-hadoop2-compat-2.0.0-alpha4.jar:/opt/hive/lib/hbase-http-2.0.0-alpha4.jar:/opt/hive/lib/hbase-mapreduce-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-2.0.0-alpha4.jar:/opt/hive/lib/hbase-metrics-api-2.0.0-alpha4.jar:/opt/hive/lib/hbase-prefix-tree-2.0.0-alpha4.jar:/opt/hive/lib/hbase-procedure-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-2.0.0-alpha4.jar:/opt/hive/lib/hbase-protocol-shaded-2.0.0-alpha4.jar:/opt/hive/lib/hbase-replication-2.0.0-alpha4.jar:/opt/hive/lib/hbase-server-2.0.0-alpha4.jar:/opt/hive/lib/hbase-shaded-miscellaneous-1.0.1.jar:/opt/hive/lib/hbase-shaded-netty-1.0.1.jar:/opt/hive/lib/hbase-shaded-protobuf-1.0.1.jar:/opt/hive/lib/hive-accumulo-handler-3.1.3.jar:/opt/hive/lib/hive-beeline-3.1.3.jar:/opt/hive/lib/hive-classification-3.1.3.jar:/opt/hive/lib/hive-cli-3.1.3.jar:/opt/hive/lib/hive-common-3.1.3.jar:/opt/hive/lib/hive-contrib-3.1.3.jar:/opt/hive/lib/hive-druid-handler-3.1.3.jar:/opt/hive/lib/hive-exec-3.1.3.jar:/opt/hive/lib/hive-hbase-handler-3.1.3.jar:/opt/hive/lib/hive-hcatalog-core-3.1.3.jar:/opt/hive/lib/hive-hcatalog-server-extensions-3.1.3.jar:/opt/hive/lib/hive-hplsql-3.1.3.jar:/opt/hive/lib/hive-jdbc-3.1.3.jar:/opt/hive/lib/hive-jdbc-handler-3.1.3.jar:/opt/hive/lib/hive-kryo-registrator-3.1.3.jar:/opt/hive/lib/hive-llap-client-3.1.3.jar:/opt/hive/lib/hive-llap-common-3.1.3-tests.jar:/opt/hive/lib/hive-llap-common-3.1.3.jar:/opt/hive/lib/hive-llap-ext-client-3.1.3.jar:/opt/hive/lib/hive-llap-server-3.1.3.jar:/opt/hive/lib/hive-llap-tez-3.1.3.jar:/opt/hive/lib/hive-metastore-3.1.3.jar:/opt/hive/lib/hive-serde-3.1.3.jar:/opt/hive/lib/hive-service-3.1.3.jar:/opt/hive/lib/hive-service-rpc-3.1.3.jar:/opt/hive/lib/hive-shims-0.23-3.1.3.jar:/opt/hive/lib/hive-shims-3.1.3.jar:/opt/hive/lib/hive-shims-common-3.1.3.jar:/opt/hive/lib/hive-shims-scheduler-3.1.3.jar:/opt/hive/lib/hive-spark-client-3.1.3.jar:/opt/hive/lib/hive-standalone-metastore-3.1.3.jar:/opt/hive/lib/hive-storage-api-2.7.0.jar:/opt/hive/lib/hive-streaming-3.1.3.jar:/opt/hive/lib/hive-testutils-3.1.3.jar:/opt/hive/lib/hive-upgrade-acid-3.1.3.jar:/opt/hive/lib/hive-vector-code-gen-3.1.3.jar:/opt/hive/lib/hk2-api-2.5.0-b32.jar:/opt/hive/lib/hk2-locator-2.5.0-b32.jar:/opt/hive/lib/hk2-utils-2.5.0-b32.jar:/opt/hive/lib/hppc-0.7.2.jar:/opt/hive/lib/htrace-core-3.2.0-incubating.jar:/opt/hive/lib/httpclient-4.5.13.jar:/opt/hive/lib/httpcore-4.4.13.jar:/opt/hive/lib/ivy-2.4.0.jar:/opt/hive/lib/jackson-annotations-2.12.0.jar:/opt/hive/lib/jackson-core-2.12.0.jar:/opt/hive/lib/jackson-core-asl-1.9.13.jar:/opt/hive/lib/jackson-databind-2.12.0.jar:/opt/hive/lib/jackson-dataformat-smile-2.12.0.jar:/opt/hive/lib/jackson-mapper-asl-1.9.13.jar:/opt/hive/lib/jackson-module-scala_2.11-2.12.0.jar:/opt/hive/lib/jamon-runtime-2.3.1.jar:/opt/hive/lib/janino-2.7.6.jar:/opt/hive/lib/javassist-3.20.0-GA.jar:/opt/hive/lib/javax.annotation-api-1.2.jar:/opt/hive/lib/javax.inject-2.5.0-b32.jar:/opt/hive/lib/javax.jdo-3.2.0-m3.jar:/opt/hive/lib/javax.servlet-api-3.1.0.jar:/opt/hive/lib/javax.servlet.jsp-2.3.2.jar:/opt/hive/lib/javax.servlet.jsp-api-2.3.1.jar:/opt/hive/lib/javax.ws.rs-api-2.0.1.jar:/opt/hive/lib/javolution-5.5.1.jar:/opt/hive/lib/jaxb-api-2.2.11.jar:/opt/hive/lib/jcodings-1.0.18.jar:/opt/hive/lib/jcommander-1.32.jar:/opt/hive/lib/jdo-api-3.0.1.jar:/opt/hive/lib/jersey-client-2.25.1.jar:/opt/hive/lib/jersey-common-2.25.1.jar:/opt/hive/lib/jersey-container-servlet-core-2.25.1.jar:/opt/hive/lib/jersey-guava-2.25.1.jar:/opt/hive/lib/jersey-media-jaxb-2.25.1.jar:/opt/hive/lib/jersey-server-2.25.1.jar:/opt/hive/lib/jettison-1.1.jar:/opt/hive/lib/jetty-annotations-9.3.20.v20170531.jar:/opt/hive/lib/jetty-client-9.3.20.v20170531.jar:/opt/hive/lib/jetty-http-9.3.20.v20170531.jar:/opt/hive/lib/jetty-io-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jaas-9.3.20.v20170531.jar:/opt/hive/lib/jetty-jndi-9.3.20.v20170531.jar:/opt/hive/lib/jetty-plus-9.3.20.v20170531.jar:/opt/hive/lib/jetty-rewrite-9.3.20.v20170531.jar:/opt/hive/lib/jetty-runner-9.3.20.v20170531.jar:/opt/hive/lib/jetty-schemas-3.1.jar:/opt/hive/lib/jetty-security-9.3.20.v20170531.jar:/opt/hive/lib/jetty-server-9.3.20.v20170531.jar:/opt/hive/lib/jetty-servlet-9.3.20.v20170531.jar:/opt/hive/lib/jetty-util-9.3.20.v20170531.jar:/opt/hive/lib/jetty-webapp-9.3.20.v20170531.jar:/opt/hive/lib/jetty-xml-9.3.20.v20170531.jar:/opt/hive/lib/jline-2.12.jar:/opt/hive/lib/joda-time-2.9.9.jar:/opt/hive/lib/jodd-core-3.5.2.jar:/opt/hive/lib/joni-2.1.11.jar:/opt/hive/lib/jpam-1.1.jar:/opt/hive/lib/json-1.8.jar:/opt/hive/lib/json4s-ast_2.11-3.2.11.jar:/opt/hive/lib/json4s-core_2.11-3.2.11.jar:/opt/hive/lib/json4s-jackson_2.11-3.2.11.jar:/opt/hive/lib/jsr305-3.0.0.jar:/opt/hive/lib/jta-1.1.jar:/opt/hive/lib/kryo-shaded-3.0.3.jar:/opt/hive/lib/libfb303-0.9.3.jar:/opt/hive/lib/libthrift-0.9.3.jar:/opt/hive/lib/lz4-java-1.4.0.jar:/opt/hive/lib/memory-0.9.0.jar:/opt/hive/lib/metrics-core-3.1.0.jar:/opt/hive/lib/metrics-graphite-3.1.5.jar:/opt/hive/lib/metrics-json-3.1.0.jar:/opt/hive/lib/metrics-jvm-3.1.0.jar:/opt/hive/lib/minlog-1.3.0.jar:/opt/hive/lib/mysql-metadata-storage-0.12.0.jar:/opt/hive/lib/netty-3.10.5.Final.jar:/opt/hive/lib/netty-all-4.1.17.Final.jar:/opt/hive/lib/netty-buffer-4.1.17.Final.jar:/opt/hive/lib/netty-common-4.1.17.Final.jar:/opt/hive/lib/objenesis-2.1.jar:/opt/hive/lib/opencsv-2.3.jar:/opt/hive/lib/opencsv-3.9.jar:/opt/hive/lib/orc-core-1.5.8.jar:/opt/hive/lib/orc-shims-1.5.8.jar:/opt/hive/lib/orc-tools-1.5.8.jar:/opt/hive/lib/org.abego.treelayout.core-1.0.1.jar:/opt/hive/lib/osgi-resource-locator-1.0.1.jar:/opt/hive/lib/paranamer-2.7.jar:/opt/hive/lib/parquet-hadoop-bundle-1.10.0.jar:/opt/hive/lib/postgresql-42.7.7.jar:/opt/hive/lib/postgresql-9.4.1208.jre7.jar:/opt/hive/lib/postgresql-metadata-storage-0.12.0.jar:/opt/hive/lib/protobuf-java-2.5.0.jar:/opt/hive/lib/py4j-0.10.6.jar:/opt/hive/lib/pyrolite-4.13.jar:/opt/hive/lib/scala-compiler-2.11.0.jar:/opt/hive/lib/scala-library-2.11.8.jar:/opt/hive/lib/scala-parser-combinators_2.11-1.0.1.jar:/opt/hive/lib/scala-reflect-2.11.0.jar:/opt/hive/lib/scala-xml_2.11-1.0.1.jar:/opt/hive/lib/scalap-2.11.0.jar:/opt/hive/lib/sketches-core-0.9.0.jar:/opt/hive/lib/snappy-java-1.1.4.jar:/opt/hive/lib/spark-core_2.11-2.3.0.jar:/opt/hive/lib/spark-kvstore_2.11-2.3.0.jar:/opt/hive/lib/spark-launcher_2.11-2.3.0.jar:/opt/hive/lib/spark-network-common_2.11-2.3.0.jar:/opt/hive/lib/spark-network-shuffle_2.11-2.3.0.jar:/opt/hive/lib/spark-tags_2.11-2.3.0.jar:/opt/hive/lib/spark-unsafe_2.11-2.3.0.jar:/opt/hive/lib/sqlline-1.3.0.jar:/opt/hive/lib/stax-api-1.0.1.jar:/opt/hive/lib/stream-2.7.0.jar:/opt/hive/lib/super-csv-2.2.0.jar:/opt/hive/lib/taglibs-standard-impl-1.2.5.jar:/opt/hive/lib/taglibs-standard-spec-1.2.5.jar:/opt/hive/lib/tempus-fugit-1.1.jar:/opt/hive/lib/threetenbp-1.3.5.jar:/opt/hive/lib/transaction-api-1.1.jar:/opt/hive/lib/unused-1.0.0.jar:/opt/hive/lib/validation-api-1.1.0.Final.jar:/opt/hive/lib/velocity-1.7.jar:/opt/hive/lib/websocket-api-9.3.20.v20170531.jar:/opt/hive/lib/websocket-client-9.3.20.v20170531.jar:/opt/hive/lib/websocket-common-9.3.20.v20170531.jar:/opt/hive/lib/websocket-server-9.3.20.v20170531.jar:/opt/hive/lib/websocket-servlet-9.3.20.v20170531.jar:/opt/hive/lib/xbean-asm5-shaded-4.4.jar:/opt/hive/lib/xz-1.5.jar:/opt/hive/lib/zookeeper-3.4.6.jar:/opt/hive/lib/zstd-jni-1.3.2-2.jar:/opt/hadoop/share/hadoop/tools/lib/hadoop-distcp-3.1.0.jar:/opt/hive/lib/log4j-1.2-api-2.17.1.jar:/opt/hive/lib/log4j-api-2.17.1.jar:/opt/hive/lib/log4j-core-2.17.1.jar:/opt/hive/lib/log4j-slf4j-impl-2.17.1.jar:/opt/hive/lib/log4j-web-2.17.1.jar:/opt/hadoop/etc/hadoop:/opt/hadoop/share/hadoop/common/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/common/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/common/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/common/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/common/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/common/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/common/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/common/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/common/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/common/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/common/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/common/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/common/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/common/lib/hamcrest-core-1.3.jar:/opt/hadoop/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/common/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/common/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/mockito-all-1.8.5.jar:/opt/hadoop/share/hadoop/common/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/common/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/common/lib/junit-4.11.jar:/opt/hadoop/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/common/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/common/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/common/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/common/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/common/lib/jsp-api-2.1.jar:/opt/hadoop/share/hadoop/common/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/opt/hadoop/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/common/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/common/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/common/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/common/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/common/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/common/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/common/hadoop-kms-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0.jar:/opt/hadoop/share/hadoop/common/hadoop-common-3.1.0-tests.jar:/opt/hadoop/share/hadoop/common/hadoop-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs:/opt/hadoop/share/hadoop/hdfs/lib/jetty-server-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpclient-4.5.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-http-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/asm-5.0.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/gson-2.2.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/zookeeper-3.4.9.jar:/opt/hadoop/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-xml-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-annotations-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/opt/hadoop/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang3-3.4.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-servlet-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-compress-1.4.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jettison-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/xz-1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-framework-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/opt/hadoop/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/opt/hadoop/share/hadoop/hdfs/lib/paranamer-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-smart-2.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-client-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/avro-1.7.7.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-util-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-lang-2.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/okio-1.6.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-databind-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/hadoop-auth-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-io-2.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-webapp-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-net-3.6.jar:/opt/hadoop/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/curator-recipes-2.12.0.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/guava-11.0.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-io-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/jetty-security-9.3.19.v20170502.jar:/opt/hadoop/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/re2j-1.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/opt/hadoop/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/opt/hadoop/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/opt/hadoop/share/hadoop/hdfs/lib/httpcore-4.4.4.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-rbf-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0-tests.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-native-client-3.1.0.jar:/opt/hadoop/share/hadoop/hdfs/hadoop-hdfs-nfs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0-tests.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.1.0.jar:/opt/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.1.0.jar:/opt/hadoop/share/hadoop/yarn:/opt/hadoop/share/hadoop/yarn/lib/javax.inject-1.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-base-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/opt/hadoop/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/opt/hadoop/share/hadoop/yarn/lib/fst-2.50.jar:/opt/hadoop/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/opt/hadoop/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/opt/hadoop/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/opt/hadoop/share/hadoop/yarn/lib/java-util-1.9.0.jar:/opt/hadoop/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/opt/hadoop/share/hadoop/yarn/lib/aopalliance-1.0.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/lib/json-io-2.5.1.jar:/opt/hadoop/share/hadoop/yarn/lib/jersey-client-1.19.jar:/opt/hadoop/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/opt/hadoop/share/hadoop/yarn/lib/dnsjava-2.1.7.jar:/opt/hadoop/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.7.8.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-registry-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-client-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-router-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-common-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-tests-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-core-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-services-api-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.1.0.jar:/opt/hadoop/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.1.0.jar
STARTUP_MSG:   build = git://MacBook-Pro.fios-router.home/Users/ngangam/commit/hive -r 4df4d75bf1e16fe0af75aad0b4179c34c07fc975; compiled by 'ngangam' on Sun Apr 3 16:58:33 EDT 2022
************************************************************/
2025-08-03T16:12:16,926  INFO [main] metastore.HiveMetaStore: Starting hive metastore on port 9083
2025-08-03T16:12:17,242  INFO [main] metastore.HiveMetaStore: 0: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:12:17,413  WARN [main] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:12:17,423  INFO [main] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:12:17,425  INFO [main] conf.MetastoreConf: Unable to find config file hivemetastore-site.xml
2025-08-03T16:12:17,425  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:12:17,426  INFO [main] conf.MetastoreConf: Unable to find config file metastore-site.xml
2025-08-03T16:12:17,426  INFO [main] conf.MetastoreConf: Found configuration file null
2025-08-03T16:12:18,041  INFO [main] hikari.HikariDataSource: HikariPool-1 - Starting...
2025-08-03T16:12:18,475  INFO [main] hikari.HikariDataSource: HikariPool-1 - Start completed.
2025-08-03T16:12:18,527  INFO [main] hikari.HikariDataSource: HikariPool-2 - Starting...
2025-08-03T16:12:18,587  INFO [main] hikari.HikariDataSource: HikariPool-2 - Start completed.
2025-08-03T16:12:18,743  INFO [main] metastore.ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
2025-08-03T16:12:18,899  INFO [main] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:12:18,901  INFO [main] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:12:22,676  INFO [main] metastore.HiveMetaStore: Added admin role in metastore
2025-08-03T16:12:22,681  INFO [main] metastore.HiveMetaStore: Added public role in metastore
2025-08-03T16:12:22,722  INFO [main] metastore.HiveMetaStore: No user is added in admin role, since config is empty
2025-08-03T16:12:22,889  INFO [main] conf.HiveConf: Found configuration file file:/opt/hive/conf/hive-site.xml
2025-08-03T16:12:23,326  INFO [main] metastore.HiveMetaStore: Starting DB backed MetaStore Server with SetUGI enabled
2025-08-03T16:12:23,343  INFO [main] metastore.HiveMetaStore: Started the new metaserver on port [9083]...
2025-08-03T16:12:23,343  INFO [main] metastore.HiveMetaStore: Options.minWorkerThreads = 200
2025-08-03T16:12:23,343  INFO [main] metastore.HiveMetaStore: Options.maxWorkerThreads = 1000
2025-08-03T16:12:23,343  INFO [main] metastore.HiveMetaStore: TCP keepalive = true
2025-08-03T16:12:23,343  INFO [main] metastore.HiveMetaStore: Enable SSL = false
2025-08-03T16:14:21,982  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: source:172.18.0.6 get_database: default
2025-08-03T16:14:22,059 ERROR [pool-6-thread-1] metastore.RetryingHMSHandler: java.lang.NoSuchMethodError: org.apache.hadoop.security.HadoopKerberosName.setRuleMechanism(Ljava/lang/String;)V
	at org.apache.hadoop.security.HadoopKerberosName.setConfiguration(HadoopKerberosName.java:84)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:315)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:300)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:575)
	at org.apache.hadoop.hive.metastore.utils.SecurityUtils.getUGI(SecurityUtils.java:74)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.logAuditEvent(HiveMetaStore.java:339)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.logInfo(HiveMetaStore.java:898)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.startFunction(HiveMetaStore.java:903)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_database(HiveMetaStore.java:1347)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.get_database(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_database.getResult(ThriftHiveMetastore.java:14424)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_database.getResult(ThriftHiveMetastore.java:14408)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2025-08-03T16:14:22,060  INFO [pool-6-thread-1] metastore.HiveMetaStore: 1: Done cleaning up thread local RawStore
2025-08-03T16:14:22,153  INFO [pool-6-thread-1] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:14:23,171  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: default
2025-08-03T16:14:23,195  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T16:14:23,198  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:14:23,199  WARN [pool-6-thread-3] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:14:23,200  INFO [pool-6-thread-3] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:14:23,245  INFO [pool-6-thread-3] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:14:23,246  INFO [pool-6-thread-3] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:14:23,273  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:14:23,274  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:14:23,278  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:14:23,293  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:14:23,294  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:14:23,298  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:14:23,313  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: global_temp
2025-08-03T16:14:23,314  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: global_temp	
2025-08-03T16:14:23,318  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.global_temp, returning NoSuchObjectException
2025-08-03T16:14:23,354  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)
2025-08-03T16:14:23,354  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_database: Database(name:smartlogistics, description:, locationUri:s3a://smart-logistics/warehouse/smartlogistics.db, parameters:{}, ownerName:spark)	
2025-08-03T16:14:23,359  WARN [pool-6-thread-3] metastore.ObjectStore: Failed to get database hive.smartlogistics, returning NoSuchObjectException
2025-08-03T16:14:24,481  INFO [pool-6-thread-3] impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-08-03T16:14:24,516  INFO [pool-6-thread-3] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-08-03T16:14:24,517  INFO [pool-6-thread-3] impl.MetricsSystemImpl: s3a-file-system metrics system started
2025-08-03T16:14:26,917  INFO [pool-6-thread-3] utils.FileUtils: Creating directory if it doesn't exist: s3a://smart-logistics/warehouse/smartlogistics.db
2025-08-03T16:14:27,656  INFO [pool-6-thread-3] impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...
2025-08-03T16:14:27,656  INFO [pool-6-thread-3] impl.MetricsSystemImpl: s3a-file-system metrics system stopped.
2025-08-03T16:14:27,657  INFO [pool-6-thread-3] impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
2025-08-03T16:15:30,035  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_databases: *
2025-08-03T16:15:30,035  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_databases: *	
2025-08-03T16:26:06,006  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: default
2025-08-03T16:26:06,006  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T16:26:06,041  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_table : tbl=hive.default.sales_order
2025-08-03T16:26:06,042  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.default.sales_order	
2025-08-03T16:26:06,098  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_database: default
2025-08-03T16:26:06,098  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: default	
2025-08-03T16:26:06,103  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: source:172.18.0.6 get_table : tbl=hive.default.sales_order
2025-08-03T16:26:06,103  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.default.sales_order	
2025-08-03T16:26:06,225  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Cleaning up thread local RawStore...
2025-08-03T16:26:06,225  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:26:06,226  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Done cleaning up thread local RawStore
2025-08-03T16:26:06,226  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:26:06,227  INFO [pool-6-thread-3] metastore.HiveMetaStore: 2: Done cleaning up thread local RawStore
2025-08-03T16:26:06,227  INFO [pool-6-thread-3] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:26:06,380  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 create_table: Table(tableName:sales_order, dbName:default, owner:spark, createTime:1754238365, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:SalesOrder, type:string, comment:null), FieldSchema(name:SalesOrderType, type:string, comment:null), FieldSchema(name:SalesOrderTypeInternalCode, type:string, comment:null), FieldSchema(name:SalesOrganization, type:string, comment:null), FieldSchema(name:DistributionChannel, type:string, comment:null), FieldSchema(name:OrganizationDivision, type:string, comment:null), FieldSchema(name:SoldToParty, type:string, comment:null), FieldSchema(name:CreationDate, type:string, comment:null), FieldSchema(name:CreatedByUser, type:string, comment:null), FieldSchema(name:LastChangeDate, type:string, comment:null), FieldSchema(name:LastChangeDateTime, type:string, comment:null), FieldSchema(name:PurchaseOrderByCustomer, type:string, comment:null), FieldSchema(name:PurchaseOrderByShipToParty, type:string, comment:null), FieldSchema(name:TotalNetAmount, type:double, comment:null), FieldSchema(name:TransactionCurrency, type:string, comment:null), FieldSchema(name:PricingDate, type:string, comment:null), FieldSchema(name:RequestedDeliveryDate, type:string, comment:null), FieldSchema(name:ShippingCondition, type:string, comment:null), FieldSchema(name:CompleteDeliveryIsDefined, type:boolean, comment:null), FieldSchema(name:ShippingType, type:string, comment:null), FieldSchema(name:IncotermsClassification, type:string, comment:null), FieldSchema(name:IncotermsTransferLocation, type:string, comment:null), FieldSchema(name:IncotermsLocation1, type:string, comment:null), FieldSchema(name:CustomerPaymentTerms, type:string, comment:null), FieldSchema(name:ReferenceSDDocument, type:string, comment:null), FieldSchema(name:ReferenceSDDocumentCategory, type:string, comment:null), FieldSchema(name:CustomerAccountAssignmentGroup, type:string, comment:null), FieldSchema(name:AccountingExchangeRate, type:string, comment:null), FieldSchema(name:CustomerGroup, type:string, comment:null), FieldSchema(name:SlsDocIsRlvtForProofOfDeliv, type:boolean, comment:null), FieldSchema(name:OverallSDProcessStatus, type:string, comment:null), FieldSchema(name:OverallTotalDeliveryStatus, type:string, comment:null), FieldSchema(name:OverallSDDocumentRejectionSts, type:string, comment:null), FieldSchema(name:BillingDocumentDate, type:timestamp, comment:null)], location:s3a://smart-logistics/silver/sales_order, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:SalesOrderDate, type:date, comment:null)], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.numPartCols=1, spark.sql.sources.schema.partCol.0=SalesOrderDate, spark.sql.sources.schema={"type":"struct","fields":[{"name":"SalesOrder","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderType","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderTypeInternalCode","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrganization","type":"string","nullable":true,"metadata":{}},{"name":"DistributionChannel","type":"string","nullable":true,"metadata":{}},{"name":"OrganizationDivision","type":"string","nullable":true,"metadata":{}},{"name":"SoldToParty","type":"string","nullable":true,"metadata":{}},{"name":"CreationDate","type":"string","nullable":true,"metadata":{}},{"name":"CreatedByUser","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDate","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDateTime","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByCustomer","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByShipToParty","type":"string","nullable":true,"metadata":{}},{"name":"TotalNetAmount","type":"double","nullable":true,"metadata":{}},{"name":"TransactionCurrency","type":"string","nullable":true,"metadata":{}},{"name":"PricingDate","type":"string","nullable":true,"metadata":{}},{"name":"RequestedDeliveryDate","type":"string","nullable":true,"metadata":{}},{"name":"ShippingCondition","type":"string","nullable":true,"metadata":{}},{"name":"CompleteDeliveryIsDefined","type":"boolean","nullable":true,"metadata":{}},{"name":"ShippingType","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsClassification","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsTransferLocation","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsLocation1","type":"string","nullable":true,"metadata":{}},{"name":"CustomerPaymentTerms","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocument","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocumentCategory","type":"string","nullable":true,"metadata":{}},{"name":"CustomerAccountAssignmentGroup","type":"string","nullable":true,"metadata":{}},{"name":"AccountingExchangeRate","type":"string","nullable":true,"metadata":{}},{"name":"CustomerGroup","type":"string","nullable":true,"metadata":{}},{"name":"SlsDocIsRlvtForProofOfDeliv","type":"boolean","nullable":true,"metadata":{}},{"name":"OverallSDProcessStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallTotalDeliveryStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallSDDocumentRejectionSts","type":"string","nullable":true,"metadata":{}},{"name":"BillingDocumentDate","type":"timestamp","nullable":true,"metadata":{}},{"name":"SalesOrderDate","type":"date","nullable":true,"metadata":{}}]}, spark.sql.create.version=3.4.1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{spark=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), ownerType:USER)
2025-08-03T16:26:06,380  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_table: Table(tableName:sales_order, dbName:default, owner:spark, createTime:1754238365, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:SalesOrder, type:string, comment:null), FieldSchema(name:SalesOrderType, type:string, comment:null), FieldSchema(name:SalesOrderTypeInternalCode, type:string, comment:null), FieldSchema(name:SalesOrganization, type:string, comment:null), FieldSchema(name:DistributionChannel, type:string, comment:null), FieldSchema(name:OrganizationDivision, type:string, comment:null), FieldSchema(name:SoldToParty, type:string, comment:null), FieldSchema(name:CreationDate, type:string, comment:null), FieldSchema(name:CreatedByUser, type:string, comment:null), FieldSchema(name:LastChangeDate, type:string, comment:null), FieldSchema(name:LastChangeDateTime, type:string, comment:null), FieldSchema(name:PurchaseOrderByCustomer, type:string, comment:null), FieldSchema(name:PurchaseOrderByShipToParty, type:string, comment:null), FieldSchema(name:TotalNetAmount, type:double, comment:null), FieldSchema(name:TransactionCurrency, type:string, comment:null), FieldSchema(name:PricingDate, type:string, comment:null), FieldSchema(name:RequestedDeliveryDate, type:string, comment:null), FieldSchema(name:ShippingCondition, type:string, comment:null), FieldSchema(name:CompleteDeliveryIsDefined, type:boolean, comment:null), FieldSchema(name:ShippingType, type:string, comment:null), FieldSchema(name:IncotermsClassification, type:string, comment:null), FieldSchema(name:IncotermsTransferLocation, type:string, comment:null), FieldSchema(name:IncotermsLocation1, type:string, comment:null), FieldSchema(name:CustomerPaymentTerms, type:string, comment:null), FieldSchema(name:ReferenceSDDocument, type:string, comment:null), FieldSchema(name:ReferenceSDDocumentCategory, type:string, comment:null), FieldSchema(name:CustomerAccountAssignmentGroup, type:string, comment:null), FieldSchema(name:AccountingExchangeRate, type:string, comment:null), FieldSchema(name:CustomerGroup, type:string, comment:null), FieldSchema(name:SlsDocIsRlvtForProofOfDeliv, type:boolean, comment:null), FieldSchema(name:OverallSDProcessStatus, type:string, comment:null), FieldSchema(name:OverallTotalDeliveryStatus, type:string, comment:null), FieldSchema(name:OverallSDDocumentRejectionSts, type:string, comment:null), FieldSchema(name:BillingDocumentDate, type:timestamp, comment:null)], location:s3a://smart-logistics/silver/sales_order, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:SalesOrderDate, type:date, comment:null)], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.numPartCols=1, spark.sql.sources.schema.partCol.0=SalesOrderDate, spark.sql.sources.schema={"type":"struct","fields":[{"name":"SalesOrder","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderType","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderTypeInternalCode","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrganization","type":"string","nullable":true,"metadata":{}},{"name":"DistributionChannel","type":"string","nullable":true,"metadata":{}},{"name":"OrganizationDivision","type":"string","nullable":true,"metadata":{}},{"name":"SoldToParty","type":"string","nullable":true,"metadata":{}},{"name":"CreationDate","type":"string","nullable":true,"metadata":{}},{"name":"CreatedByUser","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDate","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDateTime","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByCustomer","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByShipToParty","type":"string","nullable":true,"metadata":{}},{"name":"TotalNetAmount","type":"double","nullable":true,"metadata":{}},{"name":"TransactionCurrency","type":"string","nullable":true,"metadata":{}},{"name":"PricingDate","type":"string","nullable":true,"metadata":{}},{"name":"RequestedDeliveryDate","type":"string","nullable":true,"metadata":{}},{"name":"ShippingCondition","type":"string","nullable":true,"metadata":{}},{"name":"CompleteDeliveryIsDefined","type":"boolean","nullable":true,"metadata":{}},{"name":"ShippingType","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsClassification","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsTransferLocation","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsLocation1","type":"string","nullable":true,"metadata":{}},{"name":"CustomerPaymentTerms","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocument","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocumentCategory","type":"string","nullable":true,"metadata":{}},{"name":"CustomerAccountAssignmentGroup","type":"string","nullable":true,"metadata":{}},{"name":"AccountingExchangeRate","type":"string","nullable":true,"metadata":{}},{"name":"CustomerGroup","type":"string","nullable":true,"metadata":{}},{"name":"SlsDocIsRlvtForProofOfDeliv","type":"boolean","nullable":true,"metadata":{}},{"name":"OverallSDProcessStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallTotalDeliveryStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallSDDocumentRejectionSts","type":"string","nullable":true,"metadata":{}},{"name":"BillingDocumentDate","type":"timestamp","nullable":true,"metadata":{}},{"name":"SalesOrderDate","type":"date","nullable":true,"metadata":{}}]}, spark.sql.create.version=3.4.1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{spark=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), ownerType:USER)	
2025-08-03T16:26:06,381  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:26:06,381  WARN [pool-6-thread-5] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:26:06,382  INFO [pool-6-thread-5] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:26:06,385  INFO [pool-6-thread-5] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:26:06,385  INFO [pool-6-thread-5] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:26:06,402  INFO [pool-6-thread-5] impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-08-03T16:26:06,404  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-08-03T16:26:06,404  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system started
2025-08-03T16:26:06,656  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...
2025-08-03T16:26:06,656  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system stopped.
2025-08-03T16:26:06,657  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
2025-08-03T16:26:42,609  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:26:42,610  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:26:42,615  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:26:42,615  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:26:42,631  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_tables: db=smartlogistics pat=*
2025-08-03T16:26:42,631  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_tables: db=smartlogistics pat=*	
2025-08-03T16:27:26,377  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:26,378  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:45,864  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:45,864  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:45,868  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:45,868  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:27:45,872  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:45,872  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:45,875  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:45,875  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:27:45,886  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 create_table: Table(tableName:sales_order, dbName:smartlogistics, owner:spark, createTime:1754238465, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:SalesOrder, type:string, comment:null), FieldSchema(name:SalesOrderType, type:string, comment:null), FieldSchema(name:SalesOrderTypeInternalCode, type:string, comment:null), FieldSchema(name:SalesOrganization, type:string, comment:null), FieldSchema(name:DistributionChannel, type:string, comment:null), FieldSchema(name:OrganizationDivision, type:string, comment:null), FieldSchema(name:SoldToParty, type:string, comment:null), FieldSchema(name:CreationDate, type:string, comment:null), FieldSchema(name:CreatedByUser, type:string, comment:null), FieldSchema(name:LastChangeDate, type:string, comment:null), FieldSchema(name:LastChangeDateTime, type:string, comment:null), FieldSchema(name:PurchaseOrderByCustomer, type:string, comment:null), FieldSchema(name:PurchaseOrderByShipToParty, type:string, comment:null), FieldSchema(name:TotalNetAmount, type:double, comment:null), FieldSchema(name:TransactionCurrency, type:string, comment:null), FieldSchema(name:PricingDate, type:string, comment:null), FieldSchema(name:RequestedDeliveryDate, type:string, comment:null), FieldSchema(name:ShippingCondition, type:string, comment:null), FieldSchema(name:CompleteDeliveryIsDefined, type:boolean, comment:null), FieldSchema(name:ShippingType, type:string, comment:null), FieldSchema(name:IncotermsClassification, type:string, comment:null), FieldSchema(name:IncotermsTransferLocation, type:string, comment:null), FieldSchema(name:IncotermsLocation1, type:string, comment:null), FieldSchema(name:CustomerPaymentTerms, type:string, comment:null), FieldSchema(name:ReferenceSDDocument, type:string, comment:null), FieldSchema(name:ReferenceSDDocumentCategory, type:string, comment:null), FieldSchema(name:CustomerAccountAssignmentGroup, type:string, comment:null), FieldSchema(name:AccountingExchangeRate, type:string, comment:null), FieldSchema(name:CustomerGroup, type:string, comment:null), FieldSchema(name:SlsDocIsRlvtForProofOfDeliv, type:boolean, comment:null), FieldSchema(name:OverallSDProcessStatus, type:string, comment:null), FieldSchema(name:OverallTotalDeliveryStatus, type:string, comment:null), FieldSchema(name:OverallSDDocumentRejectionSts, type:string, comment:null), FieldSchema(name:BillingDocumentDate, type:timestamp, comment:null)], location:s3a://smart-logistics/silver/sales_order, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:SalesOrderDate, type:date, comment:null)], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.numPartCols=1, spark.sql.sources.schema.partCol.0=SalesOrderDate, spark.sql.sources.schema={"type":"struct","fields":[{"name":"SalesOrder","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderType","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderTypeInternalCode","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrganization","type":"string","nullable":true,"metadata":{}},{"name":"DistributionChannel","type":"string","nullable":true,"metadata":{}},{"name":"OrganizationDivision","type":"string","nullable":true,"metadata":{}},{"name":"SoldToParty","type":"string","nullable":true,"metadata":{}},{"name":"CreationDate","type":"string","nullable":true,"metadata":{}},{"name":"CreatedByUser","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDate","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDateTime","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByCustomer","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByShipToParty","type":"string","nullable":true,"metadata":{}},{"name":"TotalNetAmount","type":"double","nullable":true,"metadata":{}},{"name":"TransactionCurrency","type":"string","nullable":true,"metadata":{}},{"name":"PricingDate","type":"string","nullable":true,"metadata":{}},{"name":"RequestedDeliveryDate","type":"string","nullable":true,"metadata":{}},{"name":"ShippingCondition","type":"string","nullable":true,"metadata":{}},{"name":"CompleteDeliveryIsDefined","type":"boolean","nullable":true,"metadata":{}},{"name":"ShippingType","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsClassification","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsTransferLocation","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsLocation1","type":"string","nullable":true,"metadata":{}},{"name":"CustomerPaymentTerms","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocument","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocumentCategory","type":"string","nullable":true,"metadata":{}},{"name":"CustomerAccountAssignmentGroup","type":"string","nullable":true,"metadata":{}},{"name":"AccountingExchangeRate","type":"string","nullable":true,"metadata":{}},{"name":"CustomerGroup","type":"string","nullable":true,"metadata":{}},{"name":"SlsDocIsRlvtForProofOfDeliv","type":"boolean","nullable":true,"metadata":{}},{"name":"OverallSDProcessStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallTotalDeliveryStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallSDDocumentRejectionSts","type":"string","nullable":true,"metadata":{}},{"name":"BillingDocumentDate","type":"timestamp","nullable":true,"metadata":{}},{"name":"SalesOrderDate","type":"date","nullable":true,"metadata":{}}]}, spark.sql.create.version=3.4.1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{spark=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), ownerType:USER)
2025-08-03T16:27:45,886  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 create_table: Table(tableName:sales_order, dbName:smartlogistics, owner:spark, createTime:1754238465, lastAccessTime:0, retention:0, sd:StorageDescriptor(cols:[FieldSchema(name:SalesOrder, type:string, comment:null), FieldSchema(name:SalesOrderType, type:string, comment:null), FieldSchema(name:SalesOrderTypeInternalCode, type:string, comment:null), FieldSchema(name:SalesOrganization, type:string, comment:null), FieldSchema(name:DistributionChannel, type:string, comment:null), FieldSchema(name:OrganizationDivision, type:string, comment:null), FieldSchema(name:SoldToParty, type:string, comment:null), FieldSchema(name:CreationDate, type:string, comment:null), FieldSchema(name:CreatedByUser, type:string, comment:null), FieldSchema(name:LastChangeDate, type:string, comment:null), FieldSchema(name:LastChangeDateTime, type:string, comment:null), FieldSchema(name:PurchaseOrderByCustomer, type:string, comment:null), FieldSchema(name:PurchaseOrderByShipToParty, type:string, comment:null), FieldSchema(name:TotalNetAmount, type:double, comment:null), FieldSchema(name:TransactionCurrency, type:string, comment:null), FieldSchema(name:PricingDate, type:string, comment:null), FieldSchema(name:RequestedDeliveryDate, type:string, comment:null), FieldSchema(name:ShippingCondition, type:string, comment:null), FieldSchema(name:CompleteDeliveryIsDefined, type:boolean, comment:null), FieldSchema(name:ShippingType, type:string, comment:null), FieldSchema(name:IncotermsClassification, type:string, comment:null), FieldSchema(name:IncotermsTransferLocation, type:string, comment:null), FieldSchema(name:IncotermsLocation1, type:string, comment:null), FieldSchema(name:CustomerPaymentTerms, type:string, comment:null), FieldSchema(name:ReferenceSDDocument, type:string, comment:null), FieldSchema(name:ReferenceSDDocumentCategory, type:string, comment:null), FieldSchema(name:CustomerAccountAssignmentGroup, type:string, comment:null), FieldSchema(name:AccountingExchangeRate, type:string, comment:null), FieldSchema(name:CustomerGroup, type:string, comment:null), FieldSchema(name:SlsDocIsRlvtForProofOfDeliv, type:boolean, comment:null), FieldSchema(name:OverallSDProcessStatus, type:string, comment:null), FieldSchema(name:OverallTotalDeliveryStatus, type:string, comment:null), FieldSchema(name:OverallSDDocumentRejectionSts, type:string, comment:null), FieldSchema(name:BillingDocumentDate, type:timestamp, comment:null)], location:s3a://smart-logistics/silver/sales_order, inputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat, outputFormat:org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat, compressed:false, numBuckets:-1, serdeInfo:SerDeInfo(name:null, serializationLib:org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe, parameters:{serialization.format=1}), bucketCols:[], sortCols:[], parameters:{}, skewedInfo:SkewedInfo(skewedColNames:[], skewedColValues:[], skewedColValueLocationMaps:{})), partitionKeys:[FieldSchema(name:SalesOrderDate, type:date, comment:null)], parameters:{EXTERNAL=TRUE, spark.sql.sources.schema.numPartCols=1, spark.sql.sources.schema.partCol.0=SalesOrderDate, spark.sql.sources.schema={"type":"struct","fields":[{"name":"SalesOrder","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderType","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrderTypeInternalCode","type":"string","nullable":true,"metadata":{}},{"name":"SalesOrganization","type":"string","nullable":true,"metadata":{}},{"name":"DistributionChannel","type":"string","nullable":true,"metadata":{}},{"name":"OrganizationDivision","type":"string","nullable":true,"metadata":{}},{"name":"SoldToParty","type":"string","nullable":true,"metadata":{}},{"name":"CreationDate","type":"string","nullable":true,"metadata":{}},{"name":"CreatedByUser","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDate","type":"string","nullable":true,"metadata":{}},{"name":"LastChangeDateTime","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByCustomer","type":"string","nullable":true,"metadata":{}},{"name":"PurchaseOrderByShipToParty","type":"string","nullable":true,"metadata":{}},{"name":"TotalNetAmount","type":"double","nullable":true,"metadata":{}},{"name":"TransactionCurrency","type":"string","nullable":true,"metadata":{}},{"name":"PricingDate","type":"string","nullable":true,"metadata":{}},{"name":"RequestedDeliveryDate","type":"string","nullable":true,"metadata":{}},{"name":"ShippingCondition","type":"string","nullable":true,"metadata":{}},{"name":"CompleteDeliveryIsDefined","type":"boolean","nullable":true,"metadata":{}},{"name":"ShippingType","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsClassification","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsTransferLocation","type":"string","nullable":true,"metadata":{}},{"name":"IncotermsLocation1","type":"string","nullable":true,"metadata":{}},{"name":"CustomerPaymentTerms","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocument","type":"string","nullable":true,"metadata":{}},{"name":"ReferenceSDDocumentCategory","type":"string","nullable":true,"metadata":{}},{"name":"CustomerAccountAssignmentGroup","type":"string","nullable":true,"metadata":{}},{"name":"AccountingExchangeRate","type":"string","nullable":true,"metadata":{}},{"name":"CustomerGroup","type":"string","nullable":true,"metadata":{}},{"name":"SlsDocIsRlvtForProofOfDeliv","type":"boolean","nullable":true,"metadata":{}},{"name":"OverallSDProcessStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallTotalDeliveryStatus","type":"string","nullable":true,"metadata":{}},{"name":"OverallSDDocumentRejectionSts","type":"string","nullable":true,"metadata":{}},{"name":"BillingDocumentDate","type":"timestamp","nullable":true,"metadata":{}},{"name":"SalesOrderDate","type":"date","nullable":true,"metadata":{}}]}, spark.sql.create.version=3.4.1}, viewOriginalText:null, viewExpandedText:null, tableType:EXTERNAL_TABLE, privileges:PrincipalPrivilegeSet(userPrivileges:{spark=[PrivilegeGrantInfo(privilege:INSERT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:SELECT, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:UPDATE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true), PrivilegeGrantInfo(privilege:DELETE, createTime:-1, grantor:spark, grantorType:USER, grantOption:true)]}, groupPrivileges:null, rolePrivileges:null), ownerType:USER)	
2025-08-03T16:27:45,895  INFO [pool-6-thread-5] impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-08-03T16:27:45,896  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-08-03T16:27:45,896  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system started
2025-08-03T16:27:45,958  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...
2025-08-03T16:27:45,958  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system stopped.
2025-08-03T16:27:45,958  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
2025-08-03T16:27:52,713  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:52,713  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:52,717  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:52,717  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:52,720  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_tables: db=smartlogistics pat=*
2025-08-03T16:27:52,720  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_tables: db=smartlogistics pat=*	
2025-08-03T16:27:53,220  INFO [pool-6-thread-4] metastore.HiveMetaStore: 3: Done cleaning up thread local RawStore
2025-08-03T16:27:53,220  INFO [pool-6-thread-4] HiveMetaStore.audit: ugi=hive	ip=172.18.0.6	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:27:59,125  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:59,126  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:59,129  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:59,130  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:27:59,182  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:59,183  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:27:59,588  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:27:59,588  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:27:59,592  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:59,593  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:27:59,619  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:59,620  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:27:59,682  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_partitions : tbl=hive.smartlogistics.sales_order
2025-08-03T16:27:59,682  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_partitions : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:28:45,173  INFO [pool-6-thread-6] metastore.HiveMetaStore: 5: source:172.18.0.5 get_databases: @hive#
2025-08-03T16:28:45,173  INFO [pool-6-thread-6] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=source:172.18.0.5 get_databases: @hive#	
2025-08-03T16:28:45,174  INFO [pool-6-thread-6] metastore.HiveMetaStore: 5: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:28:45,174  WARN [pool-6-thread-6] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:28:45,174  INFO [pool-6-thread-6] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:28:45,178  INFO [pool-6-thread-6] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:28:45,178  INFO [pool-6-thread-6] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:28:45,184  INFO [pool-6-thread-6] metastore.HiveMetaStore: 5: Cleaning up thread local RawStore...
2025-08-03T16:28:45,184  INFO [pool-6-thread-6] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:28:45,184  INFO [pool-6-thread-6] metastore.HiveMetaStore: 5: Done cleaning up thread local RawStore
2025-08-03T16:28:45,184  INFO [pool-6-thread-6] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:28:49,230  INFO [pool-6-thread-7] metastore.HiveMetaStore: 6: source:172.18.0.5 get_table_metas : tbl=hive.smartlogistics.*
2025-08-03T16:28:49,230  INFO [pool-6-thread-7] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=source:172.18.0.5 get_table_metas : tbl=hive.smartlogistics.*	
2025-08-03T16:28:49,231  INFO [pool-6-thread-7] metastore.HiveMetaStore: 6: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:28:49,231  WARN [pool-6-thread-7] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:28:49,231  INFO [pool-6-thread-7] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:28:49,234  INFO [pool-6-thread-7] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:28:49,234  INFO [pool-6-thread-7] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:28:49,251  INFO [pool-6-thread-7] metastore.HiveMetaStore: 6: Cleaning up thread local RawStore...
2025-08-03T16:28:49,251  INFO [pool-6-thread-7] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:28:49,251  INFO [pool-6-thread-7] metastore.HiveMetaStore: 6: Done cleaning up thread local RawStore
2025-08-03T16:28:49,251  INFO [pool-6-thread-7] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:28:52,707  INFO [pool-6-thread-8] metastore.HiveMetaStore: 7: source:172.18.0.5 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:28:52,707  INFO [pool-6-thread-8] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=source:172.18.0.5 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:28:52,708  INFO [pool-6-thread-8] metastore.HiveMetaStore: 7: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:28:52,708  WARN [pool-6-thread-8] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:28:52,708  INFO [pool-6-thread-8] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:28:52,711  INFO [pool-6-thread-8] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:28:52,711  INFO [pool-6-thread-8] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:28:52,766  INFO [pool-6-thread-8] metastore.HiveMetaStore: 7: Cleaning up thread local RawStore...
2025-08-03T16:28:52,767  INFO [pool-6-thread-8] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:28:52,767  INFO [pool-6-thread-8] metastore.HiveMetaStore: 7: Done cleaning up thread local RawStore
2025-08-03T16:28:52,767  INFO [pool-6-thread-8] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:30:30,360  INFO [pool-6-thread-9] metastore.HiveMetaStore: 8: source:172.18.0.5 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:30:30,361  INFO [pool-6-thread-9] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=source:172.18.0.5 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:30:30,361  INFO [pool-6-thread-9] metastore.HiveMetaStore: 8: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:30:30,362  WARN [pool-6-thread-9] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:30:30,362  INFO [pool-6-thread-9] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:30:30,367  INFO [pool-6-thread-9] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:30:30,367  INFO [pool-6-thread-9] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:30:30,388  INFO [pool-6-thread-9] metastore.HiveMetaStore: 8: Cleaning up thread local RawStore...
2025-08-03T16:30:30,388  INFO [pool-6-thread-9] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:30:30,388  INFO [pool-6-thread-9] metastore.HiveMetaStore: 8: Done cleaning up thread local RawStore
2025-08-03T16:30:30,388  INFO [pool-6-thread-9] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:30:30,450  INFO [pool-6-thread-10] metastore.HiveMetaStore: 9: source:172.18.0.5 get_partition_names : tbl=hive.smartlogistics.sales_order
2025-08-03T16:30:30,450  INFO [pool-6-thread-10] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=source:172.18.0.5 get_partition_names : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:30:30,451  INFO [pool-6-thread-10] metastore.HiveMetaStore: 9: Opening raw store with implementation class:org.apache.hadoop.hive.metastore.ObjectStore
2025-08-03T16:30:30,451  WARN [pool-6-thread-10] metastore.ObjectStore: datanucleus.autoStartMechanismMode is set to unsupported value null . Setting it to value: ignored
2025-08-03T16:30:30,451  INFO [pool-6-thread-10] metastore.ObjectStore: ObjectStore, initialize called
2025-08-03T16:30:30,454  INFO [pool-6-thread-10] metastore.MetaStoreDirectSql: Using direct SQL, underlying DB is POSTGRES
2025-08-03T16:30:30,454  INFO [pool-6-thread-10] metastore.ObjectStore: Initialized ObjectStore
2025-08-03T16:30:30,479  INFO [pool-6-thread-10] metastore.HiveMetaStore: 9: Cleaning up thread local RawStore...
2025-08-03T16:30:30,480  INFO [pool-6-thread-10] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Cleaning up thread local RawStore...	
2025-08-03T16:30:30,480  INFO [pool-6-thread-10] metastore.HiveMetaStore: 9: Done cleaning up thread local RawStore
2025-08-03T16:30:30,480  INFO [pool-6-thread-10] HiveMetaStore.audit: ugi=hive	ip=172.18.0.5	cmd=Done cleaning up thread local RawStore	
2025-08-03T16:32:50,356  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:50,356  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:50,359  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:50,360  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:50,378  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:50,378  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:50,416  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:50,416  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:50,419  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:50,419  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:50,433  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:50,433  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:50,462  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:50,462  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:50,466  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:50,466  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:50,482  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:50,482  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:50,996  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:50,996  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:51,001  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,001  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,021  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:51,021  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:51,025  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,026  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,041  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,041  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,068  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,068  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,084  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,084  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,110  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,110  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,235  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: add_partitions
2025-08-03T16:32:51,236  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=add_partitions	
2025-08-03T16:32:51,267  INFO [HMSHandler #0] impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-08-03T16:32:51,269  INFO [HMSHandler #0] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-08-03T16:32:51,269  INFO [HMSHandler #0] impl.MetricsSystemImpl: s3a-file-system metrics system started
2025-08-03T16:32:51,512  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...
2025-08-03T16:32:51,513  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system stopped.
2025-08-03T16:32:51,513  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
2025-08-03T16:32:51,516  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:51,516  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:51,519  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,519  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,534  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,534  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,547  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,547  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,582  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 alter_table: hive.smartlogistics.sales_order newtbl=sales_order
2025-08-03T16:32:51,582  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 alter_table: hive.smartlogistics.sales_order newtbl=sales_order	
2025-08-03T16:32:51,586  INFO [pool-6-thread-5] impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties
2025-08-03T16:32:51,588  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).
2025-08-03T16:32:51,588  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system started
2025-08-03T16:32:51,624  WARN [pool-6-thread-5] metastore.HiveAlterHandler: Alter table not cascaded to partitions.
2025-08-03T16:32:51,650  INFO [pool-6-thread-5] impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...
2025-08-03T16:32:51,651  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system stopped.
2025-08-03T16:32:51,651  INFO [pool-6-thread-5] impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.
2025-08-03T16:32:51,660  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:32:51,661  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:32:51,664  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,665  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:32:51,680  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:32:51,681  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:33:39,029  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:33:39,030  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:33:39,033  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:33:39,033  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:33:39,043  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:33:39,044  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:33:39,159  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:33:39,159  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:33:39,162  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:33:39,162  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:33:39,173  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:33:39,174  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:33:39,203  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_partitions_by_filter : tbl=hive.smartlogistics.sales_order
2025-08-03T16:33:39,204  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_partitions_by_filter : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:33:39,261  WARN [pool-6-thread-5] metastore.MetaStoreDirectSql: Failed to execute [select "PARTITIONS"."PART_ID" from "PARTITIONS"  inner join "TBLS" on "PARTITIONS"."TBL_ID" = "TBLS"."TBL_ID"     and "TBLS"."TBL_NAME" = ?   inner join "DBS" on "TBLS"."DB_ID" = "DBS"."DB_ID"      and "DBS"."NAME" = ? inner join "PARTITION_KEY_VALS" "FILTER0" on "FILTER0"."PART_ID" = "PARTITIONS"."PART_ID" and "FILTER0"."INTEGER_IDX" = 0 where "DBS"."CTLG_NAME" = ?  and (((case when "FILTER0"."PART_KEY_VAL" <> ? then cast("FILTER0"."PART_KEY_VAL" as date) else null end) = ?))] with parameters [sales_order, smartlogistics, hive, __HIVE_DEFAULT_PARTITION__, 2023-01-01]
javax.jdo.JDODataStoreException: Error executing SQL query "select "PARTITIONS"."PART_ID" from "PARTITIONS"  inner join "TBLS" on "PARTITIONS"."TBL_ID" = "TBLS"."TBL_ID"     and "TBLS"."TBL_NAME" = ?   inner join "DBS" on "TBLS"."DB_ID" = "DBS"."DB_ID"      and "DBS"."NAME" = ? inner join "PARTITION_KEY_VALS" "FILTER0" on "FILTER0"."PART_ID" = "PARTITIONS"."PART_ID" and "FILTER0"."INTEGER_IDX" = 0 where "DBS"."CTLG_NAME" = ?  and (((case when "FILTER0"."PART_KEY_VAL" <> ? then cast("FILTER0"."PART_KEY_VAL" as date) else null end) = ?))".
	at org.datanucleus.api.jdo.NucleusJDOHelper.getJDOExceptionForNucleusException(NucleusJDOHelper.java:543) ~[datanucleus-api-jdo-4.2.4.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:391) ~[datanucleus-api-jdo-4.2.4.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.executeWithArray(JDOQuery.java:267) ~[datanucleus-api-jdo-4.2.4.jar:?]
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.executeWithArray(MetaStoreDirectSql.java:2003) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:593) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:481) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.ObjectStore$11.getSqlResult(ObjectStore.java:3889) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.ObjectStore$11.getSqlResult(ObjectStore.java:3879) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.run(ObjectStore.java:3613) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilterInternal(ObjectStore.java:3897) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilter(ObjectStore.java:3552) [hive-exec-3.1.3.jar:3.1.3]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_342]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_342]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_342]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_342]
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97) [hive-exec-3.1.3.jar:3.1.3]
	at com.sun.proxy.$Proxy25.getPartitionsByFilter(Unknown Source) [?:?]
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions_by_filter(HiveMetaStore.java:5885) [hive-exec-3.1.3.jar:3.1.3]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_342]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_342]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_342]
	at java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_342]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108) [hive-exec-3.1.3.jar:3.1.3]
	at com.sun.proxy.$Proxy26.get_partitions_by_filter(Unknown Source) [?:?]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions_by_filter.getResult(ThriftHiveMetastore.java:16234) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions_by_filter.getResult(ThriftHiveMetastore.java:16218) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107) [hive-exec-3.1.3.jar:3.1.3]
	at java.security.AccessController.doPrivileged(Native Method) ~[?:1.8.0_342]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_342]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878) [hadoop-common-3.3.1.jar:?]
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119) [hive-exec-3.1.3.jar:3.1.3]
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286) [hive-exec-3.1.3.jar:3.1.3]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [?:1.8.0_342]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [?:1.8.0_342]
	at java.lang.Thread.run(Thread.java:750) [?:1.8.0_342]
Caused by: org.postgresql.util.PSQLException: ERROR: operator does not exist: date = character varying
  Hint: No operator matches the given name and argument types. You might need to add explicit type casts.
  Position: 481
	at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2734) ~[postgresql-42.7.7.jar:42.7.7]
	at org.postgresql.core.v3.QueryExecutorImpl.processResults(QueryExecutorImpl.java:2421) ~[postgresql-42.7.7.jar:42.7.7]
	at org.postgresql.core.v3.QueryExecutorImpl.execute(QueryExecutorImpl.java:372) ~[postgresql-42.7.7.jar:42.7.7]
	at org.postgresql.jdbc.PgStatement.executeInternal(PgStatement.java:518) ~[postgresql-42.7.7.jar:42.7.7]
	at org.postgresql.jdbc.PgStatement.execute(PgStatement.java:435) ~[postgresql-42.7.7.jar:42.7.7]
	at org.postgresql.jdbc.PgPreparedStatement.executeWithFlags(PgPreparedStatement.java:196) ~[postgresql-42.7.7.jar:42.7.7]
	at org.postgresql.jdbc.PgPreparedStatement.executeQuery(PgPreparedStatement.java:139) ~[postgresql-42.7.7.jar:42.7.7]
	at com.zaxxer.hikari.pool.ProxyPreparedStatement.executeQuery(ProxyPreparedStatement.java:52) ~[HikariCP-2.6.1.jar:?]
	at com.zaxxer.hikari.pool.HikariProxyPreparedStatement.executeQuery(HikariProxyPreparedStatement.java) ~[HikariCP-2.6.1.jar:?]
	at org.datanucleus.store.rdbms.ParamLoggingPreparedStatement.executeQuery(ParamLoggingPreparedStatement.java:375) ~[datanucleus-rdbms-4.1.19.jar:?]
	at org.datanucleus.store.rdbms.SQLController.executeStatementQuery(SQLController.java:552) ~[datanucleus-rdbms-4.1.19.jar:?]
	at org.datanucleus.store.rdbms.query.SQLQuery.performExecute(SQLQuery.java:645) ~[datanucleus-rdbms-4.1.19.jar:?]
	at org.datanucleus.store.query.Query.executeQuery(Query.java:1855) ~[datanucleus-core-4.1.17.jar:?]
	at org.datanucleus.store.rdbms.query.SQLQuery.executeWithArray(SQLQuery.java:807) ~[datanucleus-rdbms-4.1.19.jar:?]
	at org.datanucleus.api.jdo.JDOQuery.executeInternal(JDOQuery.java:368) ~[datanucleus-api-jdo-4.2.4.jar:?]
	... 36 more
2025-08-03T16:33:39,277  WARN [pool-6-thread-5] metastore.ObjectStore: Falling back to ORM path due to direct SQL failure (this is not an error): See previous errors; Error executing SQL query "select "PARTITIONS"."PART_ID" from "PARTITIONS"  inner join "TBLS" on "PARTITIONS"."TBL_ID" = "TBLS"."TBL_ID"     and "TBLS"."TBL_NAME" = ?   inner join "DBS" on "TBLS"."DB_ID" = "DBS"."DB_ID"      and "DBS"."NAME" = ? inner join "PARTITION_KEY_VALS" "FILTER0" on "FILTER0"."PART_ID" = "PARTITIONS"."PART_ID" and "FILTER0"."INTEGER_IDX" = 0 where "DBS"."CTLG_NAME" = ?  and (((case when "FILTER0"."PART_KEY_VAL" <> ? then cast("FILTER0"."PART_KEY_VAL" as date) else null end) = ?))". at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.executeWithArray(MetaStoreDirectSql.java:2015) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilterInternal(MetaStoreDirectSql.java:593) at org.apache.hadoop.hive.metastore.MetaStoreDirectSql.getPartitionsViaSqlFilter(MetaStoreDirectSql.java:481) at org.apache.hadoop.hive.metastore.ObjectStore$11.getSqlResult(ObjectStore.java:3889)
2025-08-03T16:33:39,287 ERROR [pool-6-thread-5] metastore.RetryingHMSHandler: MetaException(message:Filtering is supported only on partition keys of type string)
	at org.apache.hadoop.hive.metastore.parser.ExpressionTree$FilterBuilder.setError(ExpressionTree.java:184)
	at org.apache.hadoop.hive.metastore.parser.ExpressionTree$LeafNode.getJdoFilterPushdownParam(ExpressionTree.java:437)
	at org.apache.hadoop.hive.metastore.parser.ExpressionTree$LeafNode.generateJDOFilterOverPartitions(ExpressionTree.java:355)
	at org.apache.hadoop.hive.metastore.parser.ExpressionTree$LeafNode.generateJDOFilter(ExpressionTree.java:277)
	at org.apache.hadoop.hive.metastore.parser.ExpressionTree.generateJDOFilterFragment(ExpressionTree.java:581)
	at org.apache.hadoop.hive.metastore.ObjectStore.makeQueryFilterString(ObjectStore.java:3965)
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsViaOrmFilter(ObjectStore.java:3411)
	at org.apache.hadoop.hive.metastore.ObjectStore.access$800(ObjectStore.java:248)
	at org.apache.hadoop.hive.metastore.ObjectStore$11.getJdoResult(ObjectStore.java:3895)
	at org.apache.hadoop.hive.metastore.ObjectStore$11.getJdoResult(ObjectStore.java:3879)
	at org.apache.hadoop.hive.metastore.ObjectStore$GetHelper.run(ObjectStore.java:3622)
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilterInternal(ObjectStore.java:3897)
	at org.apache.hadoop.hive.metastore.ObjectStore.getPartitionsByFilter(ObjectStore.java:3552)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RawStoreProxy.invoke(RawStoreProxy.java:97)
	at com.sun.proxy.$Proxy25.getPartitionsByFilter(Unknown Source)
	at org.apache.hadoop.hive.metastore.HiveMetaStore$HMSHandler.get_partitions_by_filter(HiveMetaStore.java:5885)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invokeInternal(RetryingHMSHandler.java:147)
	at org.apache.hadoop.hive.metastore.RetryingHMSHandler.invoke(RetryingHMSHandler.java:108)
	at com.sun.proxy.$Proxy26.get_partitions_by_filter(Unknown Source)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions_by_filter.getResult(ThriftHiveMetastore.java:16234)
	at org.apache.hadoop.hive.metastore.api.ThriftHiveMetastore$Processor$get_partitions_by_filter.getResult(ThriftHiveMetastore.java:16218)
	at org.apache.thrift.ProcessFunction.process(ProcessFunction.java:39)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:111)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor$1.run(TUGIBasedProcessor.java:107)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:422)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1878)
	at org.apache.hadoop.hive.metastore.TUGIBasedProcessor.process(TUGIBasedProcessor.java:119)
	at org.apache.thrift.server.TThreadPoolServer$WorkerProcess.run(TThreadPoolServer.java:286)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:750)

2025-08-03T16:38:06,776  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_database: smartlogistics
2025-08-03T16:38:06,777  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_database: smartlogistics	
2025-08-03T16:38:06,783  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:38:06,783  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	
2025-08-03T16:38:06,796  INFO [pool-6-thread-5] metastore.HiveMetaStore: 4: source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order
2025-08-03T16:38:06,796  INFO [pool-6-thread-5] HiveMetaStore.audit: ugi=spark	ip=172.18.0.6	cmd=source:172.18.0.6 get_table : tbl=hive.smartlogistics.sales_order	

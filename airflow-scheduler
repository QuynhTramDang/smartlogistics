
[[34m2025-08-08T09:42:12.231+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -3] Temporary failure in name resolution, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-08T09:42:14.991+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-08T09:42:15.464+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-08T09:42:15.560+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-08T09:42:15.561+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-08T09:42:15.574+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-08T09:42:15.578+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T09:42:15.582+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m

[[34m2025-08-08T09:47:25.602+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -3] Temporary failure in name resolution, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-08T09:47:27.368+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-08T09:47:27.531+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-08T09:47:27.574+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-08T09:47:27.575+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-08T09:47:27.596+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-08T09:47:27.600+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T09:47:27.604+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-08T09:47:27.676+0000[0m] {[34mscheduler_job_runner.py:[0m1621} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2025-08-08T09:52:50.119+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T09:58:11.186+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:03:04.414+0000[0m] {[34mscheduler_job_runner.py:[0m256} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2025-08-08T10:03:05.421+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [29][0m
[[34m2025-08-08T10:03:05.422+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-08T10:03:06.037+0000[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=29, status='terminated', exitcode=0, started='09:48:30') (29) terminated with exit code 0[0m
[[34m2025-08-08T10:03:06.040+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [][0m
[[34m2025-08-08T10:03:06.041+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-08T10:03:06.041+0000[0m] {[34mprocess_utils.py:[0m101} INFO[0m - Sending the signal 15 to process 29 as process group is missing.[0m
[[34m2025-08-08T10:03:06.041+0000[0m] {[34mscheduler_job_runner.py:[0m875} INFO[0m - Exited execute loop[0m

[[34m2025-08-08T10:03:40.780+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -5] No address associated with hostname, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-08T10:03:42.417+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-08T10:03:42.589+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-08T10:03:42.623+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-08T10:03:42.623+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-08T10:03:42.638+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-08T10:03:42.642+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:03:42.645+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-08T10:09:04.784+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:14:27.832+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:18:13.479+0000[0m] {[34mscheduler_job_runner.py:[0m256} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2025-08-08T10:18:14.482+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [29][0m
[[34m2025-08-08T10:18:14.482+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-08T10:18:14.976+0000[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=29, status='terminated', exitcode=0, started='10:04:43') (29) terminated with exit code 0[0m
[[34m2025-08-08T10:18:14.978+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [][0m
[[34m2025-08-08T10:18:14.978+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-08T10:18:14.979+0000[0m] {[34mprocess_utils.py:[0m101} INFO[0m - Sending the signal 15 to process 29 as process group is missing.[0m
[[34m2025-08-08T10:18:14.980+0000[0m] {[34mscheduler_job_runner.py:[0m875} INFO[0m - Exited execute loop[0m

[[34m2025-08-08T10:18:50.369+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -3] Temporary failure in name resolution, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-08T10:18:51.919+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-08T10:18:52.076+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-08T10:18:52.108+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-08T10:18:52.108+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-08T10:18:52.122+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-08T10:18:52.124+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:18:52.127+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-08T10:24:16.224+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:29:40.600+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:33:59.030+0000[0m] {[34mscheduler_job_runner.py:[0m256} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2025-08-08T10:34:00.034+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [29][0m
[[34m2025-08-08T10:34:00.035+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-08T10:34:00.449+0000[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=29, status='terminated', exitcode=0, started='10:19:59') (29) terminated with exit code 0[0m
[[34m2025-08-08T10:34:00.450+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [][0m
[[34m2025-08-08T10:34:00.451+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-08T10:34:00.451+0000[0m] {[34mprocess_utils.py:[0m101} INFO[0m - Sending the signal 15 to process 29 as process group is missing.[0m
[[34m2025-08-08T10:34:00.451+0000[0m] {[34mscheduler_job_runner.py:[0m875} INFO[0m - Exited execute loop[0m

[[34m2025-08-08T10:34:35.699+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -3] Temporary failure in name resolution, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-08T10:34:37.448+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-08T10:34:37.635+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-08T10:34:37.673+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-08T10:34:37.674+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-08T10:34:37.688+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-08T10:34:37.692+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-08T10:34:37.698+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-09T01:27:58.364+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T01:33:25.036+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T01:38:52.111+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T01:44:19.410+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T01:49:46.196+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T01:55:12.993+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:00:00.144+0000[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG silver_sales_order is at (or above) max_active_runs (1 of 1), not creating any more runs[0m
[[34m2025-08-09T02:00:00.191+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:00:00.191+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:00:00.192+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:00:00.194+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2025-08-09T02:00:00.194+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:00:00.602+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:00:00.610+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order scheduled__2025-08-08T02:00:00+00:00 [queued]> to 7e25859d-40f4-4829-9065-1f8605dc9b06[0m
[[34m2025-08-09T02:00:39.685+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:00:47.163+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_item scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:00:47.163+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:00:47.164+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_item scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:00:47.166+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_item', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2025-08-09T02:00:47.166+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_item', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:00:47.218+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_item', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:00:47.219+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:00:47.223+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:00:02.095418+00:00, run_end_date=2025-08-09 02:00:46.594734+00:00, run_duration=44.499316, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1960, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-08-09 02:00:00.192845+00:00, queued_by_job_id=1959, pid=57[0m
[[34m2025-08-09T02:00:47.224+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_item scheduled__2025-08-08T02:00:00+00:00 [queued]> to 2df01d73-03ee-4ee6-9303-24854cb8a495[0m
[[34m2025-08-09T02:03:15.233+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_partner scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:03:15.234+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:03:15.234+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_partner scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:03:15.236+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_partner', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2025-08-09T02:03:15.236+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_partner', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:03:15.279+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_partner', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:03:15.279+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_item', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:03:15.282+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_item, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:00:48.173314+00:00, run_end_date=2025-08-09 02:03:14.893214+00:00, run_duration=146.7199, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1961, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-08-09 02:00:47.164754+00:00, queued_by_job_id=1959, pid=703[0m
[[34m2025-08-09T02:03:15.283+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_partner scheduled__2025-08-08T02:00:00+00:00 [queued]> to 0d4ac15f-4196-42a6-a4be-247274fd5e72[0m
[[34m2025-08-09T02:06:51.362+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:07:03.090+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:07:03.091+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:07:03.091+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:07:03.093+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2025-08-09T02:07:03.093+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_scheduleline', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:07:03.142+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:07:03.142+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_partner', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:07:03.147+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_partner, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:03:15.990514+00:00, run_end_date=2025-08-09 02:07:02.043070+00:00, run_duration=226.052556, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1962, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-08-09 02:03:15.234997+00:00, queued_by_job_id=1959, pid=1399[0m
[[34m2025-08-09T02:07:03.148+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [queued]> to 3230fb91-3127-4879-846a-6e9d294e69f6[0m

[[34m2025-08-09T02:14:33.692+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -3] Temporary failure in name resolution, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-09T02:14:34.999+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-09T02:14:35.137+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-09T02:14:35.176+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-09T02:14:35.176+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-09T02:14:35.188+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-09T02:14:35.191+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:14:35.193+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-09T02:14:35.263+0000[0m] {[34mscheduler_job_runner.py:[0m1621} INFO[0m - Marked 1 SchedulerJob instances as failed[0m
[[34m2025-08-09T02:14:35.377+0000[0m] {[34mcelery_executor.py:[0m432} INFO[0m - Adopted the following 1 tasks from a dead executor
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [running]> in state STARTED[0m
[[34m2025-08-09T02:15:07.327+0000[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG silver_sales_order is at (or above) max_active_runs (1 of 1), not creating any more runs[0m
[[34m2025-08-09T02:15:07.367+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:15:07.367+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:15:07.368+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:15:07.371+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 6 and queue default[0m
[[34m2025-08-09T02:15:07.371+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:15:07.515+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:15:07.525+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order scheduled__2025-08-08T02:00:00+00:00 [queued]> to 8de68150-c651-4c11-a37c-19bcc39d6000[0m
[[34m2025-08-09T02:15:50.667+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_item scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:15:50.667+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:15:50.667+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_item scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:15:50.669+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_item', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 5 and queue default[0m
[[34m2025-08-09T02:15:50.669+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_item', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:15:50.713+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_item', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:15:50.713+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:15:50.717+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:15:08.142565+00:00, run_end_date=2025-08-09 02:15:50.189392+00:00, run_duration=42.046827, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1997, pool=default_pool, queue=default, priority_weight=6, operator=PythonOperator, queued_dttm=2025-08-09 02:15:07.369016+00:00, queued_by_job_id=1996, pid=57[0m
[[34m2025-08-09T02:15:50.717+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_item scheduled__2025-08-08T02:00:00+00:00 [queued]> to cd299340-f239-4d7f-affb-fc312b143a4e[0m
[[34m2025-08-09T02:16:37.807+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_partner scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:16:37.807+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:16:37.808+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_partner scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:16:37.809+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_partner', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 4 and queue default[0m
[[34m2025-08-09T02:16:37.809+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_partner', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:16:37.848+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_partner', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:16:37.849+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_item', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:16:37.852+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_item, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:15:51.342580+00:00, run_end_date=2025-08-09 02:16:36.859961+00:00, run_duration=45.517381, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1998, pool=default_pool, queue=default, priority_weight=5, operator=PythonOperator, queued_dttm=2025-08-09 02:15:50.668147+00:00, queued_by_job_id=1996, pid=691[0m
[[34m2025-08-09T02:16:37.852+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_partner scheduled__2025-08-08T02:00:00+00:00 [queued]> to 7cfa9347-f7c1-400a-a190-1fa562a3988f[0m
[[34m2025-08-09T02:17:30.275+0000[0m] {[34m__init__.py:[0m49} WARNING[0m - Failed operation _query_task_cls_from_db_backend.  Retrying 2 more times.[0m
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "airflow-db" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/celery/backends/database/__init__.py", line 47, in _inner
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/celery/executors/celery_executor_utils.py", line 291, in _query_task_cls_from_db_backend
    return session.scalars(select(task_cls).where(task_cls.task_id.in_(task_ids))).all()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "airflow-db" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2025-08-09T02:17:43.105+0000[0m] {[34m__init__.py:[0m49} WARNING[0m - Failed operation _query_task_cls_from_db_backend.  Retrying 1 more times.[0m
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
psycopg2.OperationalError: could not translate host name "airflow-db" to address: Temporary failure in name resolution


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/celery/backends/database/__init__.py", line 47, in _inner
    return fun(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/celery/executors/celery_executor_utils.py", line 291, in _query_task_cls_from_db_backend
    return session.scalars(select(task_cls).where(task_cls.task_id.in_(task_ids))).all()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1778, in scalars
    return self.execute(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1716, in execute
    conn = self._connection_for_bind(bind)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 1555, in _connection_for_bind
    return self._transaction._connection_for_bind(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/orm/session.py", line 750, in _connection_for_bind
    conn = bind.connect()
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3325, in connect
    return self._connection_cls(self, close_with_result=close_with_result)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 96, in __init__
    else engine.raw_connection()
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3404, in raw_connection
    return self._wrap_pool_connect(self.pool.connect, _connection)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3374, in _wrap_pool_connect
    Connection._handle_dbapi_exception_noconnection(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 2208, in _handle_dbapi_exception_noconnection
    util.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/base.py", line 3371, in _wrap_pool_connect
    return fn()
           ^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 327, in connect
    return _ConnectionFairy._checkout(self)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 894, in _checkout
    fairy = _ConnectionRecord.checkout(pool)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 493, in checkout
    rec = pool._do_get()
          ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/impl.py", line 256, in _do_get
    return self._create_connection()
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 273, in _create_connection
    return _ConnectionRecord(self)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 388, in __init__
    self.__connect()
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 690, in __connect
    with util.safe_reraise():
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py", line 70, in __exit__
    compat.raise_(
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/util/compat.py", line 211, in raise_
    raise exception
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/pool/base.py", line 686, in __connect
    self.dbapi_connection = connection = pool._invoke_creator(self)
                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/create.py", line 574, in connect
    return dialect.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sqlalchemy/engine/default.py", line 598, in connect
    return self.dbapi.connect(*cargs, **cparams)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/psycopg2/__init__.py", line 122, in connect
    conn = _connect(dsn, connection_factory=connection_factory, **kwasync)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
sqlalchemy.exc.OperationalError: (psycopg2.OperationalError) could not translate host name "airflow-db" to address: Temporary failure in name resolution

(Background on this error at: https://sqlalche.me/e/14/e3q8)
[[34m2025-08-09T02:17:45.612+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:17:45.613+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:17:45.613+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:17:45.616+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2025-08-09T02:17:45.616+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_scheduleline', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:17:45.627+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=1 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:45.665+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_partner', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:45.676+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_partner, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:16:39.115916+00:00, run_end_date=2025-08-09 02:17:42.824482+00:00, run_duration=63.708566, state=success, executor_state=success, try_number=1, max_tries=1, job_id=1999, pool=default_pool, queue=default, priority_weight=4, operator=PythonOperator, queued_dttm=2025-08-09 02:16:37.808418+00:00, queued_by_job_id=1996, pid=1331[0m
[[34m2025-08-09T02:17:45.816+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=2 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:47.006+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=3 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:48.063+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=4 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:49.308+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=5 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:49.591+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=6 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:50.651+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=7 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:50.792+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=8 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:51.857+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=9 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:52.916+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=10 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:53.967+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=11 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:55.472+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=12 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:56.555+0000[0m] {[34mbase_executor.py:[0m284} INFO[0m - queued but still running; attempt=13 task=TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:17:57.625+0000[0m] {[34mbase_executor.py:[0m287} ERROR[0m - could not queue task TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) (still running after 13 attempts)[0m
[[34m2025-08-09T02:19:17.588+0000[0m] {[34mscheduler_job_runner.py:[0m256} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2025-08-09T02:19:18.591+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [29][0m
[[34m2025-08-09T02:19:18.591+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-09T02:19:19.205+0000[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=29, status='terminated', exitcode=0, started='02:14:54') (29) terminated with exit code 0[0m
[[34m2025-08-09T02:19:19.220+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [][0m
[[34m2025-08-09T02:19:19.221+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-09T02:19:19.221+0000[0m] {[34mprocess_utils.py:[0m101} INFO[0m - Sending the signal 15 to process 29 as process group is missing.[0m
[[34m2025-08-09T02:19:19.221+0000[0m] {[34mscheduler_job_runner.py:[0m875} INFO[0m - Exited execute loop[0m

[[34m2025-08-09T02:19:47.985+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -2] Name or service not known, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-09T02:19:49.179+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-09T02:19:49.308+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-09T02:19:49.333+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-09T02:19:49.334+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-09T02:19:49.343+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-09T02:19:49.346+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:19:49.349+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-09T02:19:49.409+0000[0m] {[34mscheduler_job_runner.py:[0m1657} INFO[0m - Reset the following 1 orphaned TaskInstances:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [queued]>[0m
[[34m2025-08-09T02:19:49.527+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:19:49.528+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:19:49.528+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:19:49.533+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 3 and queue default[0m
[[34m2025-08-09T02:19:49.534+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_scheduleline', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:19:49.737+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:19:49.744+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_scheduleline scheduled__2025-08-08T02:00:00+00:00 [queued]> to 48aefd25-fb9c-4216-bfae-a36e390f370a[0m
[[34m2025-08-09T02:20:33.292+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_pricing_element scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:20:33.293+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:20:33.294+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_pricing_element scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:20:33.296+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_pricing_element', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 2 and queue default[0m
[[34m2025-08-09T02:20:33.296+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_pricing_element', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:20:33.353+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_pricing_element', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:20:33.354+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_scheduleline', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:20:33.360+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_scheduleline, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:19:50.290053+00:00, run_end_date=2025-08-09 02:20:32.419832+00:00, run_duration=42.129779, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2001, pool=default_pool, queue=default, priority_weight=3, operator=PythonOperator, queued_dttm=2025-08-09 02:19:49.530260+00:00, queued_by_job_id=2000, pid=1945[0m
[[34m2025-08-09T02:20:33.361+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_pricing_element scheduled__2025-08-08T02:00:00+00:00 [queued]> to 370a4035-7026-4756-8b3a-a49ccb4e174b[0m
[[34m2025-08-09T02:21:16.497+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: silver_sales_order.silver_sales_order_subsequent_proc_flow scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:21:16.497+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG silver_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:21:16.498+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: silver_sales_order.silver_sales_order_subsequent_proc_flow scheduled__2025-08-08T02:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:21:16.500+0000[0m] {[34mscheduler_job_runner.py:[0m639} INFO[0m - Sending TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_subsequent_proc_flow', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1) to executor with priority 1 and queue default[0m
[[34m2025-08-09T02:21:16.500+0000[0m] {[34mbase_executor.py:[0m149} INFO[0m - Adding to queue: ['airflow', 'tasks', 'run', 'silver_sales_order', 'silver_sales_order_subsequent_proc_flow', 'scheduled__2025-08-08T02:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/silver/silver_sale_order.py'][0m
[[34m2025-08-09T02:21:16.547+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state queued for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_subsequent_proc_flow', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:21:16.547+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_pricing_element', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:21:16.551+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_pricing_element, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:20:34.060317+00:00, run_end_date=2025-08-09 02:21:15.812463+00:00, run_duration=41.752146, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2002, pool=default_pool, queue=default, priority_weight=2, operator=PythonOperator, queued_dttm=2025-08-09 02:20:33.294822+00:00, queued_by_job_id=2000, pid=2568[0m
[[34m2025-08-09T02:21:16.552+0000[0m] {[34mscheduler_job_runner.py:[0m711} INFO[0m - Setting external_id for <TaskInstance: silver_sales_order.silver_sales_order_subsequent_proc_flow scheduled__2025-08-08T02:00:00+00:00 [queued]> to f24a6f7f-d59f-4e30-bb3a-aca23aa74626[0m
[[34m2025-08-09T02:21:56.116+0000[0m] {[34mdagrun.py:[0m850} INFO[0m - Marking run <DagRun silver_sales_order @ 2025-08-08 02:00:00+00:00: scheduled__2025-08-08T02:00:00+00:00, state:running, queued_at: 2025-08-09 02:15:07.307587+00:00. externally triggered: False> successful[0m
[[34m2025-08-09T02:21:56.117+0000[0m] {[34mdagrun.py:[0m901} INFO[0m - DagRun Finished: dag_id=silver_sales_order, execution_date=2025-08-08 02:00:00+00:00, run_id=scheduled__2025-08-08T02:00:00+00:00, run_start_date=2025-08-09 02:15:07.337797+00:00, run_end_date=2025-08-09 02:21:56.117175+00:00, run_duration=408.779378, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2025-08-08 02:00:00+00:00, data_interval_end=2025-08-09 02:00:00+00:00, dag_hash=42bc0204271d13cd30038062d124b527[0m
[[34m2025-08-09T02:21:56.124+0000[0m] {[34mdag.py:[0m3947} INFO[0m - Setting next_dagrun for silver_sales_order to 2025-08-09 02:00:00+00:00, run_after=2025-08-10 02:00:00+00:00[0m
[[34m2025-08-09T02:21:56.147+0000[0m] {[34mscheduler_job_runner.py:[0m689} INFO[0m - Received executor event with state success for task instance TaskInstanceKey(dag_id='silver_sales_order', task_id='silver_sales_order_subsequent_proc_flow', run_id='scheduled__2025-08-08T02:00:00+00:00', try_number=1, map_index=-1)[0m
[[34m2025-08-09T02:21:56.151+0000[0m] {[34mscheduler_job_runner.py:[0m721} INFO[0m - TaskInstance Finished: dag_id=silver_sales_order, task_id=silver_sales_order_subsequent_proc_flow, run_id=scheduled__2025-08-08T02:00:00+00:00, map_index=-1, run_start_date=2025-08-09 02:21:17.354289+00:00, run_end_date=2025-08-09 02:21:55.655698+00:00, run_duration=38.301409, state=success, executor_state=success, try_number=1, max_tries=1, job_id=2003, pool=default_pool, queue=default, priority_weight=1, operator=PythonOperator, queued_dttm=2025-08-09 02:21:16.498697+00:00, queued_by_job_id=2000, pid=3187[0m
[[34m2025-08-09T02:25:13.787+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:29:42.652+0000[0m] {[34mscheduler_job_runner.py:[0m256} INFO[0m - Exiting gracefully upon receiving signal 15[0m
[[34m2025-08-09T02:29:43.655+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [29][0m
[[34m2025-08-09T02:29:43.655+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-09T02:29:44.149+0000[0m] {[34mprocess_utils.py:[0m80} INFO[0m - Process psutil.Process(pid=29, status='terminated', exitcode=0, started='02:20:30') (29) terminated with exit code 0[0m
[[34m2025-08-09T02:29:44.151+0000[0m] {[34mprocess_utils.py:[0m132} INFO[0m - Sending 15 to group 29. PIDs of all processes in the group: [][0m
[[34m2025-08-09T02:29:44.151+0000[0m] {[34mprocess_utils.py:[0m87} INFO[0m - Sending the signal 15 to group 29[0m
[[34m2025-08-09T02:29:44.152+0000[0m] {[34mprocess_utils.py:[0m101} INFO[0m - Sending the signal 15 to process 29 as process group is missing.[0m
[[34m2025-08-09T02:29:44.152+0000[0m] {[34mscheduler_job_runner.py:[0m875} INFO[0m - Exited execute loop[0m

[[34m2025-08-09T02:30:22.423+0000[0m] {[34mstats.py:[0m42} ERROR[0m - Could not configure StatsClient: [Errno -3] Temporary failure in name resolution, using NoStatsLogger instead.[0m
  ____________       _____________
 ____    |__( )_________  __/__  /________      __
____  /| |_  /__  ___/_  /_ __  /_  __ \_ | /| / /
___  ___ |  / _  /   _  __/ _  / / /_/ /_ |/ |/ /
 _/_/  |_/_/  /_/    /_/    /_/  \____/____/|__/
[[34m2025-08-09T02:30:24.181+0000[0m] {[34mtask_context_logger.py:[0m63} INFO[0m - Task context logging is enabled[0m
[[34m2025-08-09T02:30:24.431+0000[0m] {[34mexecutor_loader.py:[0m235} INFO[0m - Loaded executor: CeleryExecutor[0m
[[34m2025-08-09T02:30:24.476+0000[0m] {[34mscheduler_job_runner.py:[0m799} INFO[0m - Starting the scheduler[0m
[[34m2025-08-09T02:30:24.476+0000[0m] {[34mscheduler_job_runner.py:[0m806} INFO[0m - Processing each file at most -1 times[0m
[[34m2025-08-09T02:30:24.491+0000[0m] {[34mmanager.py:[0m170} INFO[0m - Launched DagFileProcessorManager with pid: 29[0m
[[34m2025-08-09T02:30:24.494+0000[0m] {[34mscheduler_job_runner.py:[0m1598} INFO[0m - Adopting or resetting orphaned tasks for active dag runs[0m
[[34m2025-08-09T02:30:24.499+0000[0m] {[34msettings.py:[0m60} INFO[0m - Configured default timezone UTC[0m
[[34m2025-08-09T02:35:26.142+0000[0m] {[34mscheduler_job_runner.py:[0m1331} INFO[0m - DAG bronze_sales_order is at (or above) max_active_runs (1 of 1), not creating any more runs[0m
[[34m2025-08-09T02:35:26.328+0000[0m] {[34mscheduler_job_runner.py:[0m417} INFO[0m - 1 tasks up for execution:
	<TaskInstance: bronze_sales_order.get_object_names scheduled__2025-08-09T01:00:00+00:00 [scheduled]>[0m
[[34m2025-08-09T02:35:26.330+0000[0m] {[34mscheduler_job_runner.py:[0m480} INFO[0m - DAG bronze_sales_order has 0/16 running and queued tasks[0m
[[34m2025-08-09T02:35:26.331+0000[0m] {[34mscheduler_job_runner.py:[0m596} INFO[0m - Setting the following tasks to queued state:
	<TaskInstance: bronze_sales_order.get_object_names scheduled__2025-08-09T01:00:00+00:00 [scheduled]>[0m
